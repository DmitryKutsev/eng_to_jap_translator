{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled47.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPOpUERvnzgu+TFddIibGwb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DmitryKutsev/eng_to_jap_translator/blob/main/attn_seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ytt4JlBZO3M",
        "outputId": "a53dcb3b-a5a9-4a46-bfb3-496e9c32944d"
      },
      "source": [
        "!pip install tinysegmenter"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tinysegmenter\n",
            "  Downloading https://files.pythonhosted.org/packages/9c/70/488895cb11e160b548c9ba5847c171b65b86a8ca1e54d206d55b2976bf7b/tinysegmenter-0.4.tar.gz\n",
            "Building wheels for collected packages: tinysegmenter\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.4-cp36-none-any.whl size=13536 sha256=2b791a0b760ee35444e11bcfe19b24ccb409e670cdb1a4addc88e1e5f669edbe\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/71/2b/6402196bf28012826e507ef7b99df6ebd98cce78bd99023471\n",
            "Successfully built tinysegmenter\n",
            "Installing collected packages: tinysegmenter\n",
            "Successfully installed tinysegmenter-0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3F_2aqNlVxoX"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torchtext\n",
        "from torchtext.data import Field, BucketIterator, TabularDataset\n",
        "import random\n",
        "import spacy\n",
        "import tinysegmenter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNLjawCzuJXU"
      },
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI3u2k5TuXBb"
      },
      "source": [
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ1Np6TNtVY9"
      },
      "source": [
        "spacy_en = spacy.load('en')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-t9olLUZ11J"
      },
      "source": [
        "segmenter = tinysegmenter.TinySegmenter()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-CSyftcWATc"
      },
      "source": [
        "my_frame = pd.read_excel(\n",
        "'http://nlp.ist.i.kyoto-u.ac.jp/EN/?plugin=attach&refer=JEC%20Basic%20Sentence%20Data&openfile=JEC_basic_sentence_v1-2.xls')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7vAkhV_XVgK"
      },
      "source": [
        "#remove Chineese column\n",
        "my_frame = my_frame.drop(['难道不会是X吗，我实在是感到怀疑。'], axis=1)\n",
        "my_frame.columns = ['index', 'jp', 'en']\n",
        "my_frame = my_frame.drop(['index'], axis=1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOfXTtcClM7_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "ffde8ed8-88a1-490d-bfbe-d14ad50faaea"
      },
      "source": [
        "my_frame"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>jp</th>\n",
              "      <th>en</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Xがいいなといつも思います</td>\n",
              "      <td>I always think X would be nice.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>それがあるようにいつも思います</td>\n",
              "      <td>It always seems like it is there.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>それが多すぎないかと正直思う</td>\n",
              "      <td>I honestly feel like there is too much.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>山田はみんなに好かれるタイプの人だと思う</td>\n",
              "      <td>I think that Yamada is the type everybody likes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>〜と誰かが思った</td>\n",
              "      <td>Someone thought that 〜</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5298</th>\n",
              "      <td>チームが４人のメンバーで構成されています</td>\n",
              "      <td>The team consists of four members.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5299</th>\n",
              "      <td>彼が実際に動画を再生する</td>\n",
              "      <td>He actually plays the video.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5300</th>\n",
              "      <td>政府が銀行に公的資金をどんどん投入しました</td>\n",
              "      <td>The government injected massive public funds i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5301</th>\n",
              "      <td>レベル１の機能に下記の機能をプラスする</td>\n",
              "      <td>The following will be added to the level 1 fun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5302</th>\n",
              "      <td>彼が携帯を制服のポケットに仕舞う</td>\n",
              "      <td>He puts his cell phone into the pocket of his ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5303 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                         jp                                                 en\n",
              "0             Xがいいなといつも思います                    I always think X would be nice.\n",
              "1           それがあるようにいつも思います                  It always seems like it is there.\n",
              "2            それが多すぎないかと正直思う            I honestly feel like there is too much.\n",
              "3      山田はみんなに好かれるタイプの人だと思う   I think that Yamada is the type everybody likes.\n",
              "4                  〜と誰かが思った                             Someone thought that 〜\n",
              "...                     ...                                                ...\n",
              "5298   チームが４人のメンバーで構成されています                 The team consists of four members.\n",
              "5299           彼が実際に動画を再生する                       He actually plays the video.\n",
              "5300  政府が銀行に公的資金をどんどん投入しました  The government injected massive public funds i...\n",
              "5301    レベル１の機能に下記の機能をプラスする  The following will be added to the level 1 fun...\n",
              "5302       彼が携帯を制服のポケットに仕舞う  He puts his cell phone into the pocket of his ...\n",
              "\n",
              "[5303 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "867hWid-lsCx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e59bffa-fb10-46df-ed1a-4fc74b901e57"
      },
      "source": [
        "segmenter.tokenize(my_frame['jp'][1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['それ', 'が', 'ある', 'よう', 'にいつも', '思い', 'ます']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZsQH33qt4Sf",
        "outputId": "f04058ec-1610-44de-928a-4ca4176b42d0"
      },
      "source": [
        "[tok.text for tok in spacy_en.tokenizer(my_frame['en'][1])]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['It', 'always', 'seems', 'like', 'it', 'is', 'there', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiMWnSpXt4Yc"
      },
      "source": [
        "my_frame.to_csv('my_frame.csv', index=False)  "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWCcevdZtYCj"
      },
      "source": [
        "def get_datasets(batch_size=128):\n",
        "    # Download the language files\n",
        "    spacy_de = spacy.load('de')\n",
        "    spacy_en = spacy.load('en')\n",
        "\n",
        "    # define the tokenizer\n",
        "    def tokenize_jp(text):\n",
        "        \"\"\"\n",
        "        Tokenizes JP text from a string into a list of strings\n",
        "        \"\"\"\n",
        "        return segmenter.tokenize(text)\n",
        "\n",
        "        \n",
        "    def tokenize_en(text):\n",
        "        \"\"\"\n",
        "        Tokenizes English text from a string into a list of strings\n",
        "        \"\"\"\n",
        "        return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "    # Create the pytext's Field\n",
        "    source = Field(tokenize=tokenize_en, init_token='<sos>', eos_token='<eos>')\n",
        "    target = Field(tokenize=tokenize_jp, init_token='<sos>', eos_token='<eos>')\n",
        "    dataset = TabularDataset(path='my_frame.csv', \n",
        "                         format='csv', \n",
        "                         fields=[ ('jp', TRG), ('en', SRC),],\n",
        "                         skip_header=True)\n",
        "\n",
        "    # Splits the data in Train, Test and Validation data\n",
        "    train_data, valid_data, test_data = dataset.split(split_ratio=[0.7, 0.1, 0.2], \n",
        "                                            random_state=random.getstate())\n",
        "\n",
        "    # Build the vocabulary for both the language\n",
        "    source.build_vocab(train_data, min_freq=1)\n",
        "    target.build_vocab(train_data, min_freq=1)\n",
        "\n",
        "    # Create the Iterator using builtin Bucketing\n",
        "    train_iterator, valid_iterator, test_iterator = BucketIterator.splits((train_data, valid_data, test_data),\n",
        "                                                                          batch_size=batch_size,\n",
        "                                                                          sort_within_batch=True,\n",
        "                                                                          sort_key=lambda x: len(x.src),\n",
        "                                                                          device=device)\n",
        "    return train_iterator, valid_iterator, test_iterator, source, target"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZu4XaC6u2ON"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_len, embedding_dim, encoder_hidden_dim, n_layers=1, dropout_prob=0.5):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_len, embedding_dim)\n",
        "        self.rnn = nn.GRU(embedding_dim, encoder_hidden_dim, n_layers, dropout=dropout_prob)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "\n",
        "    def forward(self, input_batch):\n",
        "        embedded = self.dropout(self.embedding(input_batch))\n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "\n",
        "        return outputs, hidden"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBmfATqXvEdh"
      },
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, encoder_hidden_dim, decoder_hidden_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        # The input dimension will the the concatenation of\n",
        "        # encoder_hidden_dim (hidden) and  decoder_hidden_dim(encoder_outputs)\n",
        "        self.attn_hidden_vector = nn.Linear(encoder_hidden_dim + decoder_hidden_dim, decoder_hidden_dim)\n",
        "\n",
        "        # We need source len number of values for n batch as the dimension\n",
        "        # of the attention weights. The attn_hidden_vector will have the\n",
        "        # dimension of [source len, batch size, decoder hidden dim]\n",
        "        # If we set the output dim of this Linear layer to 1 then the\n",
        "        # effective output dimension will be [source len, batch size]\n",
        "        self.attn_scoring_fn = nn.Linear(decoder_hidden_dim, 1, bias=False)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        # hidden = [1, batch size, decoder hidden dim]\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "\n",
        "        # We need to calculate the attn_hidden for each source words.\n",
        "        # Instead of repeating this using a loop, we can duplicate\n",
        "        # hidden src_len number of times and perform the operations.\n",
        "        hidden = hidden.repeat(src_len, 1, 1)\n",
        "\n",
        "        # Calculate Attention Hidden values\n",
        "        attn_hidden = torch.tanh(self.attn_hidden_vector(torch.cat((hidden, encoder_outputs), dim=2)))\n",
        "\n",
        "        # Calculate the Scoring function. Remove 3rd dimension.\n",
        "        attn_scoring_vector = self.attn_scoring_fn(attn_hidden).squeeze(2)\n",
        "\n",
        "        # The attn_scoring_vector has dimension of [source len, batch size]\n",
        "        # Since we need to calculate the softmax per record in the batch\n",
        "        # we will switch the dimension to [batch size,source len]\n",
        "        attn_scoring_vector = attn_scoring_vector.permute(1, 0)\n",
        "\n",
        "        # Softmax function for normalizing the weights to\n",
        "        # probability distribution\n",
        "        return F.softmax(attn_scoring_vector, dim=1)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUDjF--svKCa"
      },
      "source": [
        "class OneStepDecoder(nn.Module):\n",
        "    def __init__(self, input_output_dim, embedding_dim, encoder_hidden_dim, decoder_hidden_dim, attention, dropout_prob=0.5):\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_dim = input_output_dim\n",
        "        self.attention = attention\n",
        "\n",
        "        self.embedding = nn.Embedding(input_output_dim, embedding_dim)\n",
        "\n",
        "        # Add the encoder_hidden_dim and embedding_dim\n",
        "        self.rnn = nn.GRU(encoder_hidden_dim + embedding_dim, decoder_hidden_dim)\n",
        "        # Combine all the features for better prediction\n",
        "        self.fc = nn.Linear(encoder_hidden_dim + decoder_hidden_dim + embedding_dim, input_output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        # Add the source len dimension\n",
        "        input = input.unsqueeze(0)\n",
        "\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "\n",
        "        # Calculate the attention weights\n",
        "        a = self.attention(hidden, encoder_outputs).unsqueeze(1)\n",
        "\n",
        "        # We need to perform the batch wise dot product.\n",
        "        # Hence need to shift the batch dimension to the front.\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "\n",
        "        # Use PyTorch's bmm function to calculate the\n",
        "        # weight W.\n",
        "        W = torch.bmm(a, encoder_outputs)\n",
        "\n",
        "        # Revert the batch dimension.\n",
        "        W = W.permute(1, 0, 2)\n",
        "\n",
        "        # concatenate the previous output with W\n",
        "        rnn_input = torch.cat((embedded, W), dim=2)\n",
        "\n",
        "        output, hidden = self.rnn(rnn_input, hidden)\n",
        "\n",
        "        # Remove the sentence length dimension and pass them to the Linear layer\n",
        "        predicted_token = self.fc(torch.cat((output.squeeze(0), W.squeeze(0), embedded.squeeze(0)), dim=1))\n",
        "\n",
        "        return predicted_token, hidden, a.squeeze(1)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb_ZTRXCvXvT"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, one_step_decoder, device):\n",
        "        super().__init__()\n",
        "        self.one_step_decoder = one_step_decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, target, encoder_outputs, hidden, teacher_forcing_ratio=0.5):\n",
        "        batch_size = target.shape[1]\n",
        "        trg_len = target.shape[0]\n",
        "        trg_vocab_size = self.one_step_decoder.output_dim\n",
        "\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        input = target[0, :]\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            # Pass the encoder_outputs. For the first time step the\n",
        "            # hidden state comes from the encoder model.\n",
        "            output, hidden, a = self.one_step_decoder(input, hidden, encoder_outputs)\n",
        "            outputs[t] = output\n",
        "\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.argmax(1)\n",
        "\n",
        "            input = target[t] if teacher_force else top1\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyWpxXrivcFQ"
      },
      "source": [
        "class EncodeDecoder(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, source, target, teacher_forcing_ratio=0.5):\n",
        "        encoder_outputs, hidden = self.encoder(source)\n",
        "        return self.decoder(target, encoder_outputs, hidden, teacher_forcing_ratio)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MAiAqTUA7nN"
      },
      "source": [
        "def create_model(source, target):\n",
        "    # Define the required dimensions and hyper parameters\n",
        "    embedding_dim = 256\n",
        "    hidden_dim = 1024\n",
        "    dropout = 0.5\n",
        "\n",
        "    # Instantiate the models\n",
        "    attention_model = Attention(hidden_dim, hidden_dim)\n",
        "    encoder = Encoder(len(source.vocab), embedding_dim, hidden_dim)\n",
        "    one_step_decoder = OneStepDecoder(len(target.vocab), embedding_dim, hidden_dim, hidden_dim, attention_model)\n",
        "    decoder = Decoder(one_step_decoder, device)\n",
        "\n",
        "    model = EncodeDecoder(encoder, decoder)\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Define the optimizer\n",
        "    optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "    # Makes sure the CrossEntropyLoss ignores the padding tokens.\n",
        "    TARGET_PAD_IDX = target.vocab.stoi[target.pad_token]\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=TARGET_PAD_IDX)\n",
        "\n",
        "    return model, optimizer, criterion\n",
        "    "
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmJTfi3NveB3"
      },
      "source": [
        "def train(train_iterator, valid_iterator, source, target, epochs=10):\n",
        "    model, optimizer, criterion = create_model(source, target)\n",
        "\n",
        "    clip = 1\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        pbar = tqdm(total=len(train_iterator), bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}', unit=' batches', ncols=200)\n",
        "\n",
        "        training_loss = []\n",
        "        # set training mode\n",
        "        model.train()\n",
        "\n",
        "        # Loop through the training batch\n",
        "        for i, batch in enumerate(train_iterator):\n",
        "            # Get the source and target tokens\n",
        "            src = batch.src\n",
        "            trg = batch.trg\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            output = model(src, trg)\n",
        "\n",
        "            # reshape the output\n",
        "            output_dim = output.shape[-1]\n",
        "\n",
        "            # Discard the first token as this will always be 0\n",
        "            output = output[1:].view(-1, output_dim)\n",
        "\n",
        "            # Discard the sos token from target\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            # Calculate the loss\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            # back propagation\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient Clipping for stability\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            training_loss.append(loss.item())\n",
        "\n",
        "            pbar.set_postfix(\n",
        "                epoch=f\" {epoch}, train loss= {round(sum(training_loss) / len(training_loss), 4)}\", refresh=True)\n",
        "            pbar.update()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Set the model to eval\n",
        "            model.eval()\n",
        "\n",
        "            validation_loss = []\n",
        "\n",
        "            # Loop through the validation batch\n",
        "            for i, batch in enumerate(valid_iterator):\n",
        "                src = batch.src\n",
        "                trg = batch.trg\n",
        "\n",
        "                # Forward pass\n",
        "                output = model(src, trg, 0)\n",
        "\n",
        "                output_dim = output.shape[-1]\n",
        "\n",
        "                output = output[1:].view(-1, output_dim)\n",
        "                trg = trg[1:].view(-1)\n",
        "\n",
        "                # Calculate Loss\n",
        "                loss = criterion(output, trg)\n",
        "\n",
        "                validation_loss.append(loss.item())\n",
        "\n",
        "        pbar.set_postfix(\n",
        "            epoch=f\" {epoch}, train loss= {round(sum(training_loss) / len(training_loss), 4)}, val loss= {round(sum(validation_loss) / len(validation_loss), 4)}\",\n",
        "            refresh=False)\n",
        "        pbar.close()\n",
        "\n",
        "    return model"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqftPA1QxRL2"
      },
      "source": [
        "# if __name__ == '__main__':\n",
        "train_iterator, valid_iterator, test_iterator, source, target = get_datasets(batch_size=256)\n",
        "model = train(train_iterator, valid_iterator, source, target, epochs=25)\n",
        "\n",
        "checkpoint = {\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'source': source.vocab,\n",
        "    'target': target.vocab\n",
        "}\n",
        "\n",
        "torch.save(checkpoint, 'nmt-model-gru-attention-25.pth')"
      ],
      "execution_count": 271,
      "outputs": []
    }
  ]
}