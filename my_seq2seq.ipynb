{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled47.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM3xkViVRE7JR3MGs/SL8kL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DmitryKutsev/eng_to_jap_translator/blob/main/my_seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnQDBCr5XOo-"
      },
      "source": [
        "**Neural Machine Translation.**\n",
        "\n",
        "Проект - модель генерации перевода с английского на японский. В основе лежит модель seq2seq, но если получится, то я попробую немного усложнить в дальнейшем.\n",
        "\n",
        "https://arxiv.org/pdf/1706.08198.pdf \n",
        "https://www.aclweb.org/anthology/W14-7008.pdf - статьи, на которые примерно ориентировался.\n",
        "\n",
        "В качестве токенизатора японского языка использовал tinysegmenter: https://pypi.org/project/tinysegmenter/.\n",
        "\n",
        "В качестве корпусов:\n",
        "\n",
        "Сначала корпус Kurohashi-Kawahara Lab:  http://nlp.ist.i.kyoto-u.ac.jp/EN/?JEC%20Basic%20Sentence%20Data\n",
        "\n",
        "\n",
        "Потом нашел корпус побольше, параллельный корпус англо-японских субтитров https://nlp.stanford.edu/projects/jesc/data/raw.tar.gz\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ytt4JlBZO3M",
        "outputId": "62b287b7-1dd4-4445-840e-7db7785309b5"
      },
      "source": [
        "!pip install tinysegmenter"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tinysegmenter in /usr/local/lib/python3.6/dist-packages (0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3F_2aqNlVxoX"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torchtext\n",
        "from torchtext.data import Field, BucketIterator, TabularDataset\n",
        "import random\n",
        "import spacy\n",
        "import tinysegmenter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI3u2k5TuXBb"
      },
      "source": [
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ1Np6TNtVY9"
      },
      "source": [
        "spacy_en = spacy.load('en')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-t9olLUZ11J"
      },
      "source": [
        "segmenter = tinysegmenter.TinySegmenter()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSu6zEknVPdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "544902db-fb99-459e-ece3-3c5bd92e76e9"
      },
      "source": [
        "! wget https://nlp.stanford.edu/projects/jesc/data/raw.tar.gz"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-21 15:13:21--  https://nlp.stanford.edu/projects/jesc/data/raw.tar.gz\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 102198198 (97M) [application/x-gzip]\n",
            "Saving to: ‘raw.tar.gz.1’\n",
            "\n",
            "raw.tar.gz.1        100%[===================>]  97.46M  5.54MB/s    in 13s     \n",
            "\n",
            "2020-12-21 15:13:35 (7.50 MB/s) - ‘raw.tar.gz.1’ saved [102198198/102198198]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0EV_NgMVSMh"
      },
      "source": [
        "!tar -xzf raw.tar.gz"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-TWmtS-VWVs"
      },
      "source": [
        "my_frame = pd.read_csv('raw/raw', sep='\\t')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7vAkhV_XVgK"
      },
      "source": [
        "\n",
        "my_frame.columns = ['en', 'jp']\n",
        "my_frame = my_frame[:500000]\n",
        "# my_frame = my_frame[my_frame.columns[::-1]]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOfXTtcClM7_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "3e3e33b0-1641-497b-d6e3-9ec3823543c6"
      },
      "source": [
        "my_frame"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>jp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>my opponent is shark.</td>\n",
              "      <td>俺の相手は シャークだ。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>this is one thing in exchange for another.</td>\n",
              "      <td>引き換えだ ある事とある物の</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>yeah, i'm fine.</td>\n",
              "      <td>もういいよ ごちそうさま ううん</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>don't come to the office anymore. don't call m...</td>\n",
              "      <td>もう会社には来ないでくれ 電話もするな</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>looks beautiful.</td>\n",
              "      <td>きれいだ。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499995</th>\n",
              "      <td>i was threatened by a guy from your office.</td>\n",
              "      <td>FBIの男に強要されたのに</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499996</th>\n",
              "      <td>it's distracting.</td>\n",
              "      <td>シャーペン回すんやめてくれへん? 気が散んねん。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499997</th>\n",
              "      <td>it provides a simple, inexpensive</td>\n",
              "      <td>荒れた生態系に水を</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499998</th>\n",
              "      <td>i've talked to every morgue attendant, every m...</td>\n",
              "      <td>全ての職員や運転手と話を</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499999</th>\n",
              "      <td>there's no way he was dirty.</td>\n",
              "      <td>彼が汚かったことはない</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                       en                        jp\n",
              "0                                   my opponent is shark.              俺の相手は シャークだ。\n",
              "1              this is one thing in exchange for another.            引き換えだ ある事とある物の\n",
              "2                                         yeah, i'm fine.          もういいよ ごちそうさま ううん\n",
              "3       don't come to the office anymore. don't call m...       もう会社には来ないでくれ 電話もするな\n",
              "4                                        looks beautiful.                     きれいだ。\n",
              "...                                                   ...                       ...\n",
              "499995        i was threatened by a guy from your office.             FBIの男に強要されたのに\n",
              "499996                                  it's distracting.  シャーペン回すんやめてくれへん? 気が散んねん。\n",
              "499997                  it provides a simple, inexpensive                 荒れた生態系に水を\n",
              "499998  i've talked to every morgue attendant, every m...              全ての職員や運転手と話を\n",
              "499999                       there's no way he was dirty.               彼が汚かったことはない\n",
              "\n",
              "[500000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "867hWid-lsCx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc7d0610-8978-4bf6-fbcd-f2a6e015a60e"
      },
      "source": [
        "segmenter.tokenize(my_frame['jp'][1])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['引き換え', 'だ', ' ', 'ある', '事', 'と', 'ある', '物', 'の']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZsQH33qt4Sf",
        "outputId": "8d4a0ebe-b202-4201-8672-ef6f7d10a174"
      },
      "source": [
        "[tok.text for tok in spacy_en.tokenizer(my_frame['en'][1])]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this', 'is', 'one', 'thing', 'in', 'exchange', 'for', 'another', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiMWnSpXt4Yc"
      },
      "source": [
        "my_frame.to_csv('my_frame.csv', index=False)  "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rm2SGJc8cg7M"
      },
      "source": [
        "В какой-то момент я случайно убрал MAX_LEN, о чем забыл потом, и некоторое время не мог понять, почему на полных данных модель падает."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZu4XaC6u2ON"
      },
      "source": [
        "# MAX_LEN = 25\n",
        "MAX_LEN = 15\n",
        "\n",
        "def tokenize_jp(text):\n",
        "    \"\"\"\n",
        "    Tokenizes JP text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    stops = ['  ', ' ', '...',  '「',  '、', '」', '➡',  '《', '-', '「']\n",
        "    return [i for i in segmenter.tokenize(text)[:MAX_LEN] if i not in stops]\n",
        "\n",
        "\n",
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    res = [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "    return res[:MAX_LEN]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM14NJ7Vc3G7"
      },
      "source": [
        "В качестве обработчика данных решил использовать инструменты torchtext.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBmfATqXvEdh"
      },
      "source": [
        "SRC = Field(tokenize=tokenize_en, init_token='<sos>', eos_token='<eos>')\n",
        "TRG = Field(tokenize=tokenize_jp, init_token='<sos>', eos_token='<eos>')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUDjF--svKCa"
      },
      "source": [
        "dataset = TabularDataset(path='my_frame.csv', \n",
        "                         format='csv', \n",
        "                         fields=[ ('en', SRC), ('jp', TRG)],\n",
        "                         skip_header=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb_ZTRXCvXvT"
      },
      "source": [
        "train_data, valid_data, test_data = dataset.split(split_ratio=[0.7, 0.1, 0.2], \n",
        "                                            random_state=random.getstate())"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32R_NsUacaOI"
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq=1)\n",
        "TRG.build_vocab(train_data, min_freq=1)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MAiAqTUA7nN",
        "outputId": "a7ad7ea8-991b-4cdc-8530-6caa1d806ace"
      },
      "source": [
        "print(vars(train_data.examples[0])['en'])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['have', \"n't\", 'you', 'learnt', 'to', 'speak', 'yet', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-ZYWryrI8kJ",
        "outputId": "ec4b089b-5bd8-4431-df8a-ad3d5b4a7ee6"
      },
      "source": [
        "print(vars(train_data.examples[0])['jp'])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['まだ', '言葉', 'が', '出', 'て', 'こない', 'の', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmJTfi3NveB3",
        "outputId": "e56daa63-1572-4458-c475-01ab753b309a"
      },
      "source": [
        "print (len(SRC.vocab), len(TRG.vocab))\n",
        "print (SRC.vocab.freqs.most_common(10))\n",
        "print (TRG.vocab.freqs.most_common(10))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "57123 109503\n",
            "[('.', 212448), (',', 117208), ('you', 86560), ('the', 85592), ('i', 82526), ('?', 63636), ('to', 59930), ('a', 50155), ('it', 48782), (\"'s\", 48681)]\n",
            "[('の', 129231), ('は', 97845), ('に', 86935), ('て', 79477), ('を', 74551), ('が', 68576), ('た', 65236), ('?', 48821), ('だ', 43500), ('で', 42757)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfcvmRLPvh7J"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "     batch_size = BATCH_SIZE,\n",
        "     sort_key=lambda x: len(x.jp), \n",
        "     sort_within_batch=False,\n",
        "     device = device)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4ijkRfBLlfE"
      },
      "source": [
        "\n",
        "# for b in valid_iterator:\n",
        "#     print (b.jp, b.en)\n",
        "#     sys.exit()\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIUixh0j_4I7",
        "outputId": "9ea53b81-9b79-400c-dfb2-5fad850083b1"
      },
      "source": [
        "print(vars(valid_iterator))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 256, 'train': False, 'dataset': <torchtext.data.dataset.Dataset object at 0x7f61a3b7cbe0>, 'batch_size_fn': None, 'iterations': 0, 'repeat': False, 'shuffle': False, 'sort': True, 'sort_within_batch': False, 'sort_key': <function <lambda> at 0x7f61ef62f9d8>, 'device': device(type='cpu'), 'random_shuffler': <torchtext.data.utils.RandomShuffler object at 0x7f61a36576d8>, '_iterations_this_epoch': 0, '_random_state_this_epoch': None, '_restored_from_state': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2KERuieLSKp",
        "outputId": "fcd7a821-886b-452e-c0a3-9ce11b4ff403"
      },
      "source": [
        "print(len(valid_iterator))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "391\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5WmjNVHdJLm"
      },
      "source": [
        "Раздел с самими, собственно, сетями."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUIsuJTMxazl"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src):\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(src))        \n",
        "        outputs, (hidden, cell) = self.rnn(embedded)\n",
        "\n",
        "        \n",
        "        return hidden, cell"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f1KFSFe755Z"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.output_dim = output_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden, cell):\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "                \n",
        "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
        "        \n",
        "        prediction = self.fc_out(output.squeeze(0))\n",
        "        \n",
        "        return prediction, hidden, cell"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62ouCUie7-Yq"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        \n",
        "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
        "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        assert encoder.n_layers == decoder.n_layers, \\\n",
        "            \"Encoder and decoder must have equal number of layers!\"\n",
        "        \n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        #trg = [trg len, batch size]\n",
        "        \n",
        "        batch_size = trg.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "\n",
        "        hidden, cell = self.encoder(src)\n",
        "        input = trg[0,:]\n",
        "        \n",
        "        for t in range(1, trg_len):\n",
        "\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "            outputs[t] = output\n",
        "            \n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.argmax(1) \n",
        "            input = trg[t] if teacher_force else top1\n",
        "        \n",
        "        return outputs"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8DFIOPOBiWh",
        "outputId": "3328cd69-267e-4c3d-b9e8-6ee9c51950b4"
      },
      "source": [
        "len(SRC.vocab), len(TRG.vocab)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(57123, 109503)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhRW4pSI8B33"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.4\n",
        "DEC_DROPOUT = 0.4\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnWCIOb28Eca",
        "outputId": "2c9b8aec-850a-416f-f73b-a99fc526e5be"
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "        \n",
        "model.apply(init_weights)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(57123, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.4)\n",
              "    (dropout): Dropout(p=0.4, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(109503, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.4)\n",
              "    (fc_out): Linear(in_features=512, out_features=109503, bias=True)\n",
              "    (dropout): Dropout(p=0.4, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJ9yJdDi8HQk",
        "outputId": "98dc1937-0889-4803-b5ed-df1931894a33"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 106,187,711 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NostO82q8KUa",
        "outputId": "1584b42f-e51c-4b0f-baff-158793ab54c0"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "pad_idx = TRG.vocab.stoi['<pad>']\n",
        "print(TRG.pad_token)  # <pad>\n",
        "print(TRG.vocab.stoi[TRG.pad_token]) # 1 \n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<pad>\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4TAaoFsdi3u"
      },
      "source": [
        "import time"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jU1wGUyCdsup"
      },
      "source": [
        "Обучение и оценка.\n",
        "\n",
        "Сначала я поставил progress_bar, и вроде избавился от всех его глюков в колабе, но но в какой-то момент он опять начал странно работать, и за день до дедлайна я решил, что пока ограничусь выводом результатов в принт, а progress_bar вернется, если останется время его опять чинить."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJ41zk0j8ZL8"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip, start_time):\n",
        "    \n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    my_losses = []\n",
        "    for i, batch in enumerate(iterator):\n",
        "        # progress_bar = tqdm(total=len(iterator), desc=f'{ i }')\n",
        "        src = batch.en\n",
        "        trg = batch.jp\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(src, trg)\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        my_losses.append(loss.item())\n",
        "\n",
        "        end_time = time.time()\n",
        "\n",
        "        iter_mins, iter_secs = epoch_time(start_time, end_time)\n",
        "        if i%10 == 0:\n",
        "          print(f'fmean losses: { np.mean(my_losses[-1000:]) } ', \n",
        "                f'iter { i }, iter mins { iter_mins }' )\n",
        "        if int(iter_mins) > 240:\n",
        "          return epoch_loss / len(iterator)\n",
        "        # progress_bar.set_postfix(loss=np.mean(my_losses[-1000:]),\n",
        "                            # perplexity=np.exp(np.mean(my_losses[-1000:])))\n",
        "        # progress_bar.update()\n",
        "     # progress_bar.close()\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vo20BXfSF4lg"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.en\n",
        "            trg = batch.jp\n",
        "\n",
        "            output = model(src, trg, 0) \n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35jnuevHF6zH"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Uz8gbaRyqlp"
      },
      "source": [
        "import time"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eu90fN4X3S_Y"
      },
      "source": [
        "\n",
        "# for instance in list(tqdm._instances):\n",
        "#   tqdm._decr_instances(instance)\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zx58AftzP4RQ",
        "outputId": "bbc65acd-a52e-470c-8697-255d11026cb6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zddV9-FLeaL_"
      },
      "source": [
        "Это проход уже по полным данным, что у меня некоторое время вообще не получалось.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaoXwxnfF8xF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4400d1d2-2a06-47d1-a4f3-559e96bc8526"
      },
      "source": [
        "N_EPOCHS = 4\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "total_start_time = time.time()\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP, total_start_time)\n",
        "    # valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    # if valid_loss < best_valid_loss:\n",
        "    #     best_valid_loss = valid_loss\n",
        "    #     torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    # print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fmean losses: 11.616617202758789  iter 0, iter mins 0\n",
            "fmean losses: 9.406983809037643  iter 10, iter mins 8\n",
            "fmean losses: 8.204867340269542  iter 20, iter mins 16\n",
            "fmean losses: 7.7271245371910835  iter 30, iter mins 23\n",
            "fmean losses: 7.460367633075249  iter 40, iter mins 31\n",
            "fmean losses: 7.289077338050394  iter 50, iter mins 39\n",
            "fmean losses: 7.166350904058238  iter 60, iter mins 46\n",
            "fmean losses: 7.0747798865949605  iter 70, iter mins 54\n",
            "fmean losses: 7.002428702366205  iter 80, iter mins 62\n",
            "fmean losses: 6.941084086239993  iter 90, iter mins 70\n",
            "fmean losses: 6.888884567978359  iter 100, iter mins 78\n",
            "fmean losses: 6.842120419751416  iter 110, iter mins 85\n",
            "fmean losses: 6.8014748904330675  iter 120, iter mins 93\n",
            "fmean losses: 6.767732176161904  iter 130, iter mins 101\n",
            "fmean losses: 6.732066702335439  iter 140, iter mins 109\n",
            "fmean losses: 6.70623956768718  iter 150, iter mins 116\n",
            "fmean losses: 6.682018508081851  iter 160, iter mins 124\n",
            "fmean losses: 6.659398499985187  iter 170, iter mins 132\n",
            "fmean losses: 6.639186967143696  iter 180, iter mins 140\n",
            "fmean losses: 6.616966901649355  iter 190, iter mins 147\n",
            "fmean losses: 6.599343418481931  iter 200, iter mins 155\n",
            "fmean losses: 6.580554042382263  iter 210, iter mins 163\n",
            "fmean losses: 6.561947367309984  iter 220, iter mins 171\n",
            "fmean losses: 6.543476323544721  iter 230, iter mins 178\n",
            "fmean losses: 6.52811408537552  iter 240, iter mins 186\n",
            "fmean losses: 6.515213354650247  iter 250, iter mins 194\n",
            "fmean losses: 6.502407094071194  iter 260, iter mins 202\n",
            "fmean losses: 6.488450974116026  iter 270, iter mins 209\n",
            "fmean losses: 6.474330323446688  iter 280, iter mins 217\n",
            "fmean losses: 6.4616393059799355  iter 290, iter mins 225\n",
            "fmean losses: 6.448582288038691  iter 300, iter mins 233\n",
            "fmean losses: 6.438362929598695  iter 310, iter mins 240\n",
            "Epoch: 01 | Time: 241m 33s\n",
            "\tTrain Loss: 1.468 | Train PPL:   4.341\n",
            "fmean losses: 6.020284652709961  iter 0, iter mins 242\n",
            "Epoch: 02 | Time: 0m 50s\n",
            "\tTrain Loss: 0.004 | Train PPL:   1.004\n",
            "fmean losses: 5.997544288635254  iter 0, iter mins 243\n",
            "Epoch: 03 | Time: 0m 46s\n",
            "\tTrain Loss: 0.004 | Train PPL:   1.004\n",
            "fmean losses: 6.0322747230529785  iter 0, iter mins 244\n",
            "Epoch: 04 | Time: 0m 50s\n",
            "\tTrain Loss: 0.004 | Train PPL:   1.004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wh-VuR25gMxC"
      },
      "source": [
        "def translate_sentence(sentence,src_field,trg_field,model,device, max_len=50):\n",
        "    model.eval()\n",
        "\n",
        "    if isinstance(sentence,str):\n",
        "        nlp = spacy.load('en')\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "\n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        hidden, cell = model.encoder(src_tensor)\n",
        "\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    #\n",
        "    for i in range(max_len):\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, hidden, cell = model.decoder(trg_tensor, hidden, cell)\n",
        "        pred_token = output.argmax(1).item()\n",
        "        trg_indexes.append(pred_token)\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "\n",
        "    return trg_tokens[1:-1] # remove <sos> and <eos>"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMrCC7JrgR6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d9307f3-bfcf-43a5-e4c9-1e0642d3e150"
      },
      "source": [
        "example_idx = 24\n",
        "\n",
        "src = vars(train_data.examples[example_idx])['en']\n",
        "trg = vars(train_data.examples[example_idx])['jp']\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')\n",
        "\n",
        "translation = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['he', 'used', 'to', 'tell', 'me', 'a', 'story', 'when', 'i', 'was', 'young', '...']\n",
            "trg = ['子供', 'の', '頃', 'よく', '聞か', 'さ', 'れ', 'た', 'よ', '。']\n",
            "predicted trg = ['私', 'の', 'は', 'の', 'の', 'の', 'の', 'の', 'の']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLAEyJe2ellX"
      },
      "source": [
        "По визуальной оценке результат просто ужасный. Видимо, я слишком высоко поднял фильтрацию повторяющихся слов(сейчас ве, что меньше 4х - фильтруется.)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk0HkTcEQIrL"
      },
      "source": [
        "model_save_name = 'tut1-model.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4FKTMgMn_BO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ab2b551-91bd-40a8-c9d8-60185a79cdd8"
      },
      "source": [
        "translation2 = translate_sentence('I go to school', SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = { \" \".join(translation2) } ')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted trg = 私 の の \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZG1b4gY98R3d",
        "outputId": "5a19ec3b-e259-4c53-8541-782317d4d6b3"
      },
      "source": [
        "translation2 = translate_sentence('I want to eat and drink', SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = { \" \".join(translation2) }')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted trg = 私 の の の の\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTrvLAGx8Ms5",
        "outputId": "fa24b2cb-37de-41cc-98bb-57dd483059cc"
      },
      "source": [
        "translation2 = translate_sentence('I hate school and study', SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = { \" \".join(translation2) } ')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted trg = 私 の の の \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glObHF7zlPsn"
      },
      "source": [
        "В качестве оценки использовал метрику bleu, а реализацию взял из библиотеки NLTK\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZR3kSGRiLrt"
      },
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from nltk.translate import bleu_score"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWwvW_sjgMHM",
        "outputId": "18f68cd1-261e-4649-8508-c72066366daa"
      },
      "source": [
        "for i in train_data.examples[:3]:\n",
        "  print(vars(i)['jp'])\n",
        "  #print(vars(i)['en'])\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['まだ', '言葉', 'が', '出', 'て', 'こない', 'の', '?']\n",
            "['放浪', '者', 'さん', '私', 'たち', '会っ', 'た', 'こと', 'ある', 'と', '思う', '?']\n",
            "['えっ', 'さっき', 'の', '人', 'だ', 'よね', '?', '名札', '見え', 'てる', '。']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28m6on818d71"
      },
      "source": [
        "def cal_bleu_score(dataset_pairs):\n",
        "    targets = []\n",
        "    predictions = []\n",
        " \n",
        "    for i in dataset_pairs:\n",
        "        target = vars(i)['jp']\n",
        "        target = ' '.join(target)\n",
        "        predicted_words = translate_sentence(vars(i)['en'], SRC, TRG, model, device)\n",
        "        predictions.append(' '.join(predicted_words))\n",
        "        targets.append(target)\n",
        "    print(predictions[:3])\n",
        "    print(targets[:3])\n",
        "    print(f'BLEU Score: {round(corpus_bleu(predictions, targets) * 100, 2)}')"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv96m6eFj3nr"
      },
      "source": [
        "len(valid_data.examples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TjhaUmPgc4J"
      },
      "source": [
        "cal_bleu_score(valid_data.examples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzAGNHZ9Z_RN"
      },
      "source": [
        "cal_bleu_score(train_data.examples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPLjw-7lk8s3"
      },
      "source": [
        "На всякий случай сохраню этот вариант, и попробую переобучить,если успею."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLWO-Vbd0OyP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}