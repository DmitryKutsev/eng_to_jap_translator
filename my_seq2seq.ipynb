{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled47.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMSva8vE0m8mLz/MNaH52ab",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DmitryKutsev/eng_to_jap_translator/blob/main/my_seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnQDBCr5XOo-"
      },
      "source": [
        "**Neural Machine Translation.**\n",
        "\n",
        "Проект - модель генерации перевода с английского на японский. В основе лежит модель seq2seq, но если получится, то я попробую немного усложнить в дальнейшем.\n",
        "\n",
        "https://arxiv.org/pdf/1706.08198.pdf \n",
        "https://www.aclweb.org/anthology/W14-7008.pdf - статьи, на которые примерно ориентировался.\n",
        "\n",
        "В качестве токенизатора японского языка использовал tinysegmenter: https://pypi.org/project/tinysegmenter/.\n",
        "\n",
        "В качестве корпусов:\n",
        "\n",
        "Сначала корпус Kurohashi-Kawahara Lab:  http://nlp.ist.i.kyoto-u.ac.jp/EN/?JEC%20Basic%20Sentence%20Data\n",
        "\n",
        "\n",
        "Потом нашел корпус побольше, параллельный корпус англо-японских субтитров https://nlp.stanford.edu/projects/jesc/data/raw.tar.gz\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ytt4JlBZO3M",
        "outputId": "795cb2de-2805-4e00-db89-c1406456fb18"
      },
      "source": [
        "!pip install tinysegmenter"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tinysegmenter\n",
            "  Downloading https://files.pythonhosted.org/packages/9c/70/488895cb11e160b548c9ba5847c171b65b86a8ca1e54d206d55b2976bf7b/tinysegmenter-0.4.tar.gz\n",
            "Building wheels for collected packages: tinysegmenter\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.4-cp36-none-any.whl size=13537 sha256=f2ebe8de3daffd46f4d8b46ecf3144ac458bcc71bf51e00f44b5b231aeef7030\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/71/2b/6402196bf28012826e507ef7b99df6ebd98cce78bd99023471\n",
            "Successfully built tinysegmenter\n",
            "Installing collected packages: tinysegmenter\n",
            "Successfully installed tinysegmenter-0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3F_2aqNlVxoX"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torchtext\n",
        "from torchtext.data import Field, BucketIterator, TabularDataset\n",
        "import random\n",
        "import spacy\n",
        "import tinysegmenter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI3u2k5TuXBb"
      },
      "source": [
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ1Np6TNtVY9"
      },
      "source": [
        "spacy_en = spacy.load('en')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-t9olLUZ11J"
      },
      "source": [
        "segmenter = tinysegmenter.TinySegmenter()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSu6zEknVPdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34486201-a5e0-4cda-ff49-ff8d679e9091"
      },
      "source": [
        "! wget https://nlp.stanford.edu/projects/jesc/data/raw.tar.gz"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-20 08:16:02--  https://nlp.stanford.edu/projects/jesc/data/raw.tar.gz\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 102198198 (97M) [application/x-gzip]\n",
            "Saving to: ‘raw.tar.gz’\n",
            "\n",
            "raw.tar.gz          100%[===================>]  97.46M  28.1MB/s    in 5.7s    \n",
            "\n",
            "2020-12-20 08:16:08 (17.0 MB/s) - ‘raw.tar.gz’ saved [102198198/102198198]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0EV_NgMVSMh"
      },
      "source": [
        "!tar -xzf raw.tar.gz"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-TWmtS-VWVs"
      },
      "source": [
        "my_frame = pd.read_csv('raw/raw', sep='\\t')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7vAkhV_XVgK"
      },
      "source": [
        "\n",
        "my_frame.columns = ['en', 'jp']\n",
        "my_frame = my_frame[:400000]\n",
        "my_frame = my_frame[my_frame.columns[::-1]]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOfXTtcClM7_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "fba1caba-09f4-4202-ec28-8bae0385f230"
      },
      "source": [
        "my_frame"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>jp</th>\n",
              "      <th>en</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>俺の相手は シャークだ。</td>\n",
              "      <td>my opponent is shark.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>引き換えだ ある事とある物の</td>\n",
              "      <td>this is one thing in exchange for another.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>もういいよ ごちそうさま ううん</td>\n",
              "      <td>yeah, i'm fine.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>もう会社には来ないでくれ 電話もするな</td>\n",
              "      <td>don't come to the office anymore. don't call m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>きれいだ。</td>\n",
              "      <td>looks beautiful.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399995</th>\n",
              "      <td>電話がインターネット接続しようとしてる</td>\n",
              "      <td>my phone is dialing for an internet connection.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399996</th>\n",
              "      <td>手札から アブサード・スティーラーを召喚!</td>\n",
              "      <td>i summon absurd stealer from my hand!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399997</th>\n",
              "      <td>いいえ その学位については</td>\n",
              "      <td>yes, about your double degree.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399998</th>\n",
              "      <td>似てるって思うんだけどね。</td>\n",
              "      <td>i think...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399999</th>\n",
              "      <td>タクト君 昔よりも元気そう</td>\n",
              "      <td>takutokun, you're looking better than you used...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                           jp                                                 en\n",
              "0                俺の相手は シャークだ。                              my opponent is shark.\n",
              "1              引き換えだ ある事とある物の         this is one thing in exchange for another.\n",
              "2            もういいよ ごちそうさま ううん                                    yeah, i'm fine.\n",
              "3         もう会社には来ないでくれ 電話もするな  don't come to the office anymore. don't call m...\n",
              "4                       きれいだ。                                   looks beautiful.\n",
              "...                       ...                                                ...\n",
              "399995    電話がインターネット接続しようとしてる    my phone is dialing for an internet connection.\n",
              "399996  手札から アブサード・スティーラーを召喚!              i summon absurd stealer from my hand!\n",
              "399997          いいえ その学位については                     yes, about your double degree.\n",
              "399998          似てるって思うんだけどね。                                         i think...\n",
              "399999          タクト君 昔よりも元気そう  takutokun, you're looking better than you used...\n",
              "\n",
              "[400000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "867hWid-lsCx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fdf044d-1e05-4d27-b391-f617192e4131"
      },
      "source": [
        "segmenter.tokenize(my_frame['jp'][1])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['引き換え', 'だ', ' ', 'ある', '事', 'と', 'ある', '物', 'の']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZsQH33qt4Sf",
        "outputId": "d915e927-1dc7-4e74-d1d4-cbb5c807abf9"
      },
      "source": [
        "[tok.text for tok in spacy_en.tokenizer(my_frame['en'][1])]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this', 'is', 'one', 'thing', 'in', 'exchange', 'for', 'another', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiMWnSpXt4Yc"
      },
      "source": [
        "my_frame.to_csv('my_frame.csv', index=False)  "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rm2SGJc8cg7M"
      },
      "source": [
        "В какой-то момент я случайно убрал MAX_LEN, о чем забыл потом, и некоторое время не мог понять, почему на полных данных модель падает."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZu4XaC6u2ON"
      },
      "source": [
        "# MAX_LEN = 25\n",
        "MAX_LEN = 20\n",
        "\n",
        "def tokenize_jp(text):\n",
        "    \"\"\"\n",
        "    Tokenizes JP text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    return segmenter.tokenize(text)[:MAX_LEN]\n",
        "\n",
        "\n",
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    res = [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "    return res[:MAX_LEN]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM14NJ7Vc3G7"
      },
      "source": [
        "В качестве обработчика данных решил использовать инструменты torchtext.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBmfATqXvEdh"
      },
      "source": [
        "SRC = Field(tokenize=tokenize_en, init_token='<sos>', eos_token='<eos>')\n",
        "TRG = Field(tokenize=tokenize_jp, init_token='<sos>', eos_token='<eos>')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUDjF--svKCa"
      },
      "source": [
        "dataset = TabularDataset(path='my_frame.csv', \n",
        "                         format='csv', \n",
        "                         fields=[ ('jp', TRG), ('en', SRC),],\n",
        "                         skip_header=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb_ZTRXCvXvT"
      },
      "source": [
        "train_data, valid_data, test_data = dataset.split(split_ratio=[0.7, 0.1, 0.2], \n",
        "                                            random_state=random.getstate())"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32R_NsUacaOI"
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq=2)\n",
        "TRG.build_vocab(train_data, min_freq=2)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MAiAqTUA7nN",
        "outputId": "f2d49f65-1046-4e36-ca21-d4e929e490dc"
      },
      "source": [
        "print(vars(train_data.examples[0])['en'])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['for', 'the', 'countless', ',', 'countless', 'hours']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmJTfi3NveB3",
        "outputId": "3958c6b8-4b1a-42b6-beaa-a97a64a38bbe"
      },
      "source": [
        "print (len(SRC.vocab), len(TRG.vocab))\n",
        "print (SRC.vocab.freqs.most_common(10))\n",
        "print (TRG.vocab.freqs.most_common(10))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14188 23113\n",
            "[('.', 181545), (',', 95628), ('you', 70645), ('the', 70065), ('i', 66790), ('?', 52947), ('to', 49348), ('a', 41064), ('it', 39733), (\"'s\", 39706)]\n",
            "[(' ', 199404), ('の', 107014), ('は', 80117), ('に', 71958), ('て', 66374), ('を', 61525), ('が', 57002), ('た', 56237), ('?', 41254), ('。', 37468)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfcvmRLPvh7J"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "     batch_size = BATCH_SIZE,\n",
        "     sort_key=lambda x: len(x.jp), \n",
        "     sort_within_batch=False,\n",
        "     device = device)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4ijkRfBLlfE"
      },
      "source": [
        "\n",
        "# for b in valid_iterator:\n",
        "#     print (b.jp, b.en)\n",
        "#     sys.exit()\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIUixh0j_4I7",
        "outputId": "7483be10-ba23-4472-af7f-bd89684325b8"
      },
      "source": [
        "print(vars(valid_iterator))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 256, 'train': False, 'dataset': <torchtext.data.dataset.Dataset object at 0x7fe2b0c85f28>, 'batch_size_fn': None, 'iterations': 0, 'repeat': False, 'shuffle': False, 'sort': True, 'sort_within_batch': False, 'sort_key': <function <lambda> at 0x7fe2d4aa60d0>, 'device': device(type='cpu'), 'random_shuffler': <torchtext.data.utils.RandomShuffler object at 0x7fe2b0603860>, '_iterations_this_epoch': 0, '_random_state_this_epoch': None, '_restored_from_state': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2KERuieLSKp",
        "outputId": "b2eb7497-1cbf-4974-8d04-ea50ef4eabb2"
      },
      "source": [
        "print(len(valid_iterator))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5WmjNVHdJLm"
      },
      "source": [
        "Раздел с самими, собственно, сетями."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUIsuJTMxazl"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src):\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(src))        \n",
        "        outputs, (hidden, cell) = self.rnn(embedded)\n",
        "\n",
        "        \n",
        "        return hidden, cell"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f1KFSFe755Z"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.output_dim = output_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden, cell):\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "                \n",
        "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
        "        \n",
        "        prediction = self.fc_out(output.squeeze(0))\n",
        "        \n",
        "        return prediction, hidden, cell"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62ouCUie7-Yq"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        \n",
        "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
        "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        assert encoder.n_layers == decoder.n_layers, \\\n",
        "            \"Encoder and decoder must have equal number of layers!\"\n",
        "        \n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        #trg = [trg len, batch size]\n",
        "        \n",
        "        batch_size = trg.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "\n",
        "        hidden, cell = self.encoder(src)\n",
        "        input = trg[0,:]\n",
        "        \n",
        "        for t in range(1, trg_len):\n",
        "\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "            outputs[t] = output\n",
        "            \n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.argmax(1) \n",
        "            input = trg[t] if teacher_force else top1\n",
        "        \n",
        "        return outputs"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8DFIOPOBiWh",
        "outputId": "600ad5cc-7ac7-4f1c-e024-48e3ec4e8478"
      },
      "source": [
        "len(SRC.vocab), len(TRG.vocab)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14188, 23113)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhRW4pSI8B33"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.6\n",
        "DEC_DROPOUT = 0.6\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnWCIOb28Eca",
        "outputId": "ab51d64b-5474-45aa-ff5f-7fcde50b84b0"
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "        \n",
        "model.apply(init_weights)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(14188, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.6)\n",
              "    (dropout): Dropout(p=0.6, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(23113, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.6)\n",
              "    (fc_out): Linear(in_features=512, out_features=23113, bias=True)\n",
              "    (dropout): Dropout(p=0.6, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJ9yJdDi8HQk",
        "outputId": "a11ac8d1-461c-422f-b36e-1998c6c591c6"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 28,762,441 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NostO82q8KUa",
        "outputId": "d7c8d8f9-11a1-42ed-fe77-316c1fd3d621"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "pad_idx = TRG.vocab.stoi['<pad>']\n",
        "print(TRG.pad_token)  # <pad>\n",
        "print(TRG.vocab.stoi[TRG.pad_token]) # 1 \n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<pad>\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4TAaoFsdi3u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jU1wGUyCdsup"
      },
      "source": [
        "Обучение и оценка.\n",
        "\n",
        "Сначала я поставил progress_bar, и вроде избавился от всех его глюков в колабе, но но в какой-то момент он опять начал странно работать, и за день до дедлайна я решил, что пока ограничусь выводом результатов в принт, а progress_bar вернется, если останется время его опять чинить."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJ41zk0j8ZL8"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    my_losses = []\n",
        "    for i, batch in enumerate(iterator):\n",
        "        # progress_bar = tqdm(total=len(iterator), desc=f'{ i }')\n",
        "        src = batch.en\n",
        "        trg = batch.jp\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(src, trg)\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        my_losses.append(loss.item())\n",
        "        if i%10 == 0:\n",
        "          print(f'fmean losses: { np.mean(my_losses[-1000:]) } ', f'iter { i }' )\n",
        "        # progress_bar.set_postfix(loss=np.mean(my_losses[-1000:]),\n",
        "                            # perplexity=np.exp(np.mean(my_losses[-1000:])))\n",
        "        # progress_bar.update()\n",
        "     # progress_bar.close()\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vo20BXfSF4lg"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.en\n",
        "            trg = batch.jp\n",
        "\n",
        "            output = model(src, trg, 0) \n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35jnuevHF6zH"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Uz8gbaRyqlp"
      },
      "source": [
        "import time"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eu90fN4X3S_Y"
      },
      "source": [
        "\n",
        "# for instance in list(tqdm._instances):\n",
        "#   tqdm._decr_instances(instance)\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zx58AftzP4RQ",
        "outputId": "4adc5583-2bae-4d13-d543-9a82b42f761c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zddV9-FLeaL_"
      },
      "source": [
        "Это проход уже по полным данным, что у меня некоторое время вообще не получалось.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaoXwxnfF8xF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fdf50d3-0974-4066-ff53-fcf68aacbfe2"
      },
      "source": [
        "N_EPOCHS = 1\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    # valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    # if valid_loss < best_valid_loss:\n",
        "    #     best_valid_loss = valid_loss\n",
        "    #     torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    # print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fmean losses: 10.038658142089844  iter 0\n",
            "fmean losses: 7.954061074690386  iter 10\n",
            "fmean losses: 7.035599981035505  iter 20\n",
            "fmean losses: 6.681584742761427  iter 30\n",
            "fmean losses: 6.484833356810779  iter 40\n",
            "fmean losses: 6.355862037808287  iter 50\n",
            "fmean losses: 6.268964658018018  iter 60\n",
            "fmean losses: 6.197297022376262  iter 70\n",
            "fmean losses: 6.146051548145436  iter 80\n",
            "fmean losses: 6.1046259481828296  iter 90\n",
            "fmean losses: 6.0671673104314525  iter 100\n",
            "fmean losses: 6.033696432371397  iter 110\n",
            "fmean losses: 6.005044014985896  iter 120\n",
            "fmean losses: 5.979149829340345  iter 130\n",
            "fmean losses: 5.953744878160193  iter 140\n",
            "fmean losses: 5.933502566735476  iter 150\n",
            "fmean losses: 5.916575526598818  iter 160\n",
            "fmean losses: 5.8988558367679  iter 170\n",
            "fmean losses: 5.885104582454618  iter 180\n",
            "fmean losses: 5.869276341343426  iter 190\n",
            "fmean losses: 5.855923384576294  iter 200\n",
            "fmean losses: 5.84154014677798  iter 210\n",
            "fmean losses: 5.829636603998383  iter 220\n",
            "fmean losses: 5.817247064598711  iter 230\n",
            "fmean losses: 5.807545335460995  iter 240\n",
            "fmean losses: 5.796599359626314  iter 250\n",
            "fmean losses: 5.785773818063554  iter 260\n",
            "fmean losses: 5.776411054759008  iter 270\n",
            "fmean losses: 5.765806873498014  iter 280\n",
            "fmean losses: 5.755993140112493  iter 290\n",
            "fmean losses: 5.745584440389741  iter 300\n",
            "fmean losses: 5.735737638074869  iter 310\n",
            "fmean losses: 5.727866043554288  iter 320\n",
            "fmean losses: 5.720600782204251  iter 330\n",
            "fmean losses: 5.712178902891724  iter 340\n",
            "fmean losses: 5.7031996786764205  iter 350\n",
            "fmean losses: 5.693715306860589  iter 360\n",
            "fmean losses: 5.685621519937027  iter 370\n",
            "fmean losses: 5.677614834052059  iter 380\n",
            "fmean losses: 5.6702012540129445  iter 390\n",
            "fmean losses: 5.663728660478854  iter 400\n",
            "fmean losses: 5.655845824239318  iter 410\n",
            "fmean losses: 5.648770690247452  iter 420\n",
            "fmean losses: 5.641725934021987  iter 430\n",
            "fmean losses: 5.6355998402550105  iter 440\n",
            "fmean losses: 5.62855728449684  iter 450\n",
            "fmean losses: 5.621785075959311  iter 460\n",
            "fmean losses: 5.615732903693132  iter 470\n",
            "fmean losses: 5.6091934549089775  iter 480\n",
            "fmean losses: 5.604498743768136  iter 490\n",
            "fmean losses: 5.597859495890117  iter 500\n",
            "fmean losses: 5.591470338593724  iter 510\n",
            "fmean losses: 5.585159317316799  iter 520\n",
            "fmean losses: 5.579268559673187  iter 530\n",
            "fmean losses: 5.572497509764215  iter 540\n",
            "fmean losses: 5.5672312977093315  iter 550\n",
            "fmean losses: 5.561729619847262  iter 560\n",
            "fmean losses: 5.556524661710509  iter 570\n",
            "fmean losses: 5.550290422062045  iter 580\n",
            "fmean losses: 5.546287595519761  iter 590\n",
            "fmean losses: 5.54070921467862  iter 600\n",
            "fmean losses: 5.535673054852775  iter 610\n",
            "fmean losses: 5.53048291951178  iter 620\n",
            "fmean losses: 5.525283969903333  iter 630\n",
            "fmean losses: 5.520346465981137  iter 640\n",
            "fmean losses: 5.515209627224736  iter 650\n",
            "fmean losses: 5.509699556001556  iter 660\n",
            "fmean losses: 5.505515199482175  iter 670\n",
            "fmean losses: 5.50142150968532  iter 680\n",
            "fmean losses: 5.497281393335456  iter 690\n",
            "fmean losses: 5.49259504271982  iter 700\n",
            "fmean losses: 5.48888441413096  iter 710\n",
            "fmean losses: 5.485151304782016  iter 720\n",
            "fmean losses: 5.481379728799968  iter 730\n",
            "fmean losses: 5.477536955021332  iter 740\n",
            "fmean losses: 5.474102119313734  iter 750\n",
            "fmean losses: 5.470104335328752  iter 760\n",
            "fmean losses: 5.46583628870943  iter 770\n",
            "fmean losses: 5.461072707450954  iter 780\n",
            "fmean losses: 5.45762383199371  iter 790\n",
            "fmean losses: 5.453653441535102  iter 800\n",
            "fmean losses: 5.4494216392131385  iter 810\n",
            "fmean losses: 5.445754120904549  iter 820\n",
            "fmean losses: 5.442498383252342  iter 830\n",
            "fmean losses: 5.438454908082941  iter 840\n",
            "fmean losses: 5.434985337330228  iter 850\n",
            "fmean losses: 5.431186162636255  iter 860\n",
            "fmean losses: 5.427798744731601  iter 870\n",
            "fmean losses: 5.423878600459364  iter 880\n",
            "fmean losses: 5.419671066147176  iter 890\n",
            "fmean losses: 5.416750002912887  iter 900\n",
            "fmean losses: 5.414377149713811  iter 910\n",
            "fmean losses: 5.411001973250531  iter 920\n",
            "fmean losses: 5.4078193002817585  iter 930\n",
            "fmean losses: 5.404534644452216  iter 940\n",
            "fmean losses: 5.401282519572165  iter 950\n",
            "fmean losses: 5.3982627280172775  iter 960\n",
            "fmean losses: 5.39518255799487  iter 970\n",
            "fmean losses: 5.391998832014358  iter 980\n",
            "fmean losses: 5.389367181044655  iter 990\n",
            "fmean losses: 5.3812162556648255  iter 1000\n",
            "fmean losses: 5.3547823948860165  iter 1010\n",
            "fmean losses: 5.345325263023376  iter 1020\n",
            "fmean losses: 5.336285549640656  iter 1030\n",
            "fmean losses: 5.327724290370941  iter 1040\n",
            "fmean losses: 5.320072548866272  iter 1050\n",
            "fmean losses: 5.312267478466034  iter 1060\n",
            "fmean losses: 5.304921630859375  iter 1070\n",
            "fmean losses: 5.297899510383606  iter 1080\n",
            "fmean losses: 5.2912015299797055  iter 1090\n",
            "Epoch: 01 | Time: 306m 32s\n",
            "\tTrain Loss: 5.358 | Train PPL: 212.348\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wh-VuR25gMxC"
      },
      "source": [
        "def translate_sentence(sentence,src_field,trg_field,model,device, max_len=50):\n",
        "    model.eval()\n",
        "\n",
        "    if isinstance(sentence,str):\n",
        "        nlp = spacy.load('en')\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "\n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        hidden, cell = model.encoder(src_tensor)\n",
        "\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    #\n",
        "    for i in range(max_len):\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, hidden, cell = model.decoder(trg_tensor, hidden, cell)\n",
        "        pred_token = output.argmax(1).item()\n",
        "        trg_indexes.append(pred_token)\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "\n",
        "    return trg_tokens[1:-1] # remove <sos> and <eos>"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMrCC7JrgR6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db109812-8b9b-43c6-eb63-859c9ba3ed24"
      },
      "source": [
        "example_idx = 24\n",
        "\n",
        "src = vars(train_data.examples[example_idx])['en']\n",
        "trg = vars(train_data.examples[example_idx])['jp']\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')\n",
        "\n",
        "translation = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['you', 'always', 'had', 'a', 'reason', '?']\n",
            "trg = ['あん', 'た', 'は', 'いつも', '理由', 'が', 'あっ', 'た', 'の', '?']\n",
            "predicted trg = ['<unk>', 'は', ' ', 'の', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLAEyJe2ellX"
      },
      "source": [
        "По визуальной оценке результат просто ужасный. Видимо, я слишком высоко поднял фильтрацию повторяющихся слов(сейчас ве, что меньше 4х - фильтруется.)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk0HkTcEQIrL"
      },
      "source": [
        "model_save_name = 'tut1-model.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4FKTMgMn_BO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07af818a-e726-44fe-b009-483c16709941"
      },
      "source": [
        "translation2 = translate_sentence('I go to school', SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation2}')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted trg = ['<unk>', 'の', '<unk>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZG1b4gY98R3d",
        "outputId": "df21a55a-c101-4006-bcaa-e55c6c1e0568"
      },
      "source": [
        "translation2 = translate_sentence('I want to eat and drink', SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation2}')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted trg = ['<unk>', 'の', ' ', 'に', ' ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTrvLAGx8Ms5",
        "outputId": "cd17eba9-f91b-4f09-b0ae-f3e3766aab23"
      },
      "source": [
        "translation2 = translate_sentence('I hate school and study', SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation2}')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted trg = ['<unk>', 'の', ' ', 'の', ' ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glObHF7zlPsn"
      },
      "source": [
        "В качестве оценки использовал метрику bleu из библиотеки NLTK\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZR3kSGRiLrt"
      },
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from nltk.translate import bleu_score"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWwvW_sjgMHM",
        "outputId": "6a465cf1-fe7d-4e95-b3a2-4d8d77972446"
      },
      "source": [
        "for i in train_data.examples[:3]:\n",
        "  print(vars(i)['jp'])\n",
        "  print(vars(i)['en'])\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['数え切れ', 'ない', '程', ' ', '長い', '時間', 'を']\n",
            "['for', 'the', 'countless', ',', 'countless', 'hours']\n",
            "['つまりね', ' ', 'この', '仕事', 'で', ' ', '大嫌い', 'な', 'こと', 'は', 'たく', 'さん', 'ある', 'わ']\n",
            "['i', 'mean', ',', 'there', \"'s\", 'a', 'lot', 'of', 'things', 'about', 'this', 'job', 'that', 'i', 'hate']\n",
            "['啊', ' ', '没什', '么']\n",
            "['i', \"'m\", 'sorry']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28m6on818d71"
      },
      "source": [
        "def cal_bleu_score(dataset_pairs):\n",
        "    targets = []\n",
        "    predictions = []\n",
        " \n",
        "    for i in dataset_pairs:\n",
        "        target = vars(i)['jp']\n",
        "        target = ' '.join(target)\n",
        "        predicted_words = translate_sentence(vars(i)['en'], SRC, TRG, model, device)\n",
        "        predictions.append(' '.join(predicted_words))\n",
        "        targets.append(target)\n",
        "    print(predictions[:3])\n",
        "    print(targets[:3])\n",
        "    print(f'BLEU Score: {round(corpus_bleu(predictions, targets) * 100, 2)}')"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hv96m6eFj3nr",
        "outputId": "a84e105e-7e71-4c22-fd74-86416cb988dd"
      },
      "source": [
        "len(valid_data.examples)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TjhaUmPgc4J",
        "outputId": "a81d6fbb-d7d6-4b71-c415-a9eae1661268"
      },
      "source": [
        "cal_bleu_score(valid_data.examples)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk> の     <unk> の', '<unk> の <unk> の  ', '<unk> の                              ']\n",
            "['♪   道選 べる', 'そこ で 私 は', '「表 に は 出 て こない 大物 と も コネ が ある の よ 」']\n",
            "BLEU Score: 49.37\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPLjw-7lk8s3"
      },
      "source": [
        "На всякий случай сохраню этот вариант, и попробую переобучить,если успею."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHPZkIaoijhR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}