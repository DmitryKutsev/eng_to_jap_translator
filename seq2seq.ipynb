{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled47.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPOFZlKBy7/be2P+6KvWY+j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DmitryKutsev/eng_to_jap_translator/blob/main/seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ytt4JlBZO3M",
        "outputId": "3ffdf3b2-0924-4743-d729-caf0f2b2c4b9"
      },
      "source": [
        "!pip install tinysegmenter"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tinysegmenter\n",
            "  Downloading https://files.pythonhosted.org/packages/9c/70/488895cb11e160b548c9ba5847c171b65b86a8ca1e54d206d55b2976bf7b/tinysegmenter-0.4.tar.gz\n",
            "Building wheels for collected packages: tinysegmenter\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.4-cp36-none-any.whl size=13536 sha256=66ad807abf7160285b5828579a263eff6beb3126ed3a284ab63b7e91a2247573\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/71/2b/6402196bf28012826e507ef7b99df6ebd98cce78bd99023471\n",
            "Successfully built tinysegmenter\n",
            "Installing collected packages: tinysegmenter\n",
            "Successfully installed tinysegmenter-0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3F_2aqNlVxoX",
        "outputId": "c04a825b-0058-4305-8270-256a9765d6d6"
      },
      "source": [
        "import torch\n",
        "import torch.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import tinysegmenter\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "import re\n",
        "import time\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "print(torch.__version__)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.7.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-t9olLUZ11J"
      },
      "source": [
        "segmenter = tinysegmenter.TinySegmenter()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-CSyftcWATc"
      },
      "source": [
        "my_frame = pd.read_excel(\n",
        "'http://nlp.ist.i.kyoto-u.ac.jp/EN/?plugin=attach&refer=JEC%20Basic%20Sentence%20Data&openfile=JEC_basic_sentence_v1-2.xls')"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7vAkhV_XVgK"
      },
      "source": [
        "#remove Chineese column\n",
        "my_frame = my_frame.drop(['难道不会是X吗，我实在是感到怀疑。'], axis=1)\n",
        "my_frame.columns = ['index', 'jap', 'eng']\n",
        "my_frame = my_frame.drop(['index'], axis=1)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9W4x1ggkZxw"
      },
      "source": [
        "for i in range(len(my_frame)):\n",
        "  my_frame['jap'][i] = '<start>' +  my_frame['jap'][i] + '<end>'\n",
        "  my_frame['eng'][i] = '<start>' + my_frame['eng'][i] + '<end>'"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOfXTtcClM7_",
        "outputId": "19366bab-e639-4900-b5ff-a3e4fdf4b03c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "my_frame"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>jap</th>\n",
              "      <th>eng</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;start&gt;Xがいいなといつも思います&lt;end&gt;</td>\n",
              "      <td>&lt;start&gt;I always think X would be nice.&lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;start&gt;それがあるようにいつも思います&lt;end&gt;</td>\n",
              "      <td>&lt;start&gt;It always seems like it is there.&lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;start&gt;それが多すぎないかと正直思う&lt;end&gt;</td>\n",
              "      <td>&lt;start&gt;I honestly feel like there is too much....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;start&gt;山田はみんなに好かれるタイプの人だと思う&lt;end&gt;</td>\n",
              "      <td>&lt;start&gt;I think that Yamada is the type everybo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;start&gt;〜と誰かが思った&lt;end&gt;</td>\n",
              "      <td>&lt;start&gt;Someone thought that 〜&lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5298</th>\n",
              "      <td>&lt;start&gt;チームが４人のメンバーで構成されています&lt;end&gt;</td>\n",
              "      <td>&lt;start&gt;The team consists of four members.&lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5299</th>\n",
              "      <td>&lt;start&gt;彼が実際に動画を再生する&lt;end&gt;</td>\n",
              "      <td>&lt;start&gt;He actually plays the video.&lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5300</th>\n",
              "      <td>&lt;start&gt;政府が銀行に公的資金をどんどん投入しました&lt;end&gt;</td>\n",
              "      <td>&lt;start&gt;The government injected massive public ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5301</th>\n",
              "      <td>&lt;start&gt;レベル１の機能に下記の機能をプラスする&lt;end&gt;</td>\n",
              "      <td>&lt;start&gt;The following will be added to the leve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5302</th>\n",
              "      <td>&lt;start&gt;彼が携帯を制服のポケットに仕舞う&lt;end&gt;</td>\n",
              "      <td>&lt;start&gt;He puts his cell phone into the pocket ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5303 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    jap                                                eng\n",
              "0             <start>Xがいいなといつも思います<end>        <start>I always think X would be nice.<end>\n",
              "1           <start>それがあるようにいつも思います<end>      <start>It always seems like it is there.<end>\n",
              "2            <start>それが多すぎないかと正直思う<end>  <start>I honestly feel like there is too much....\n",
              "3      <start>山田はみんなに好かれるタイプの人だと思う<end>  <start>I think that Yamada is the type everybo...\n",
              "4                  <start>〜と誰かが思った<end>                 <start>Someone thought that 〜<end>\n",
              "...                                 ...                                                ...\n",
              "5298   <start>チームが４人のメンバーで構成されています<end>     <start>The team consists of four members.<end>\n",
              "5299           <start>彼が実際に動画を再生する<end>           <start>He actually plays the video.<end>\n",
              "5300  <start>政府が銀行に公的資金をどんどん投入しました<end>  <start>The government injected massive public ...\n",
              "5301    <start>レベル１の機能に下記の機能をプラスする<end>  <start>The following will be added to the leve...\n",
              "5302       <start>彼が携帯を制服のポケットに仕舞う<end>  <start>He puts his cell phone into the pocket ...\n",
              "\n",
              "[5303 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "867hWid-lsCx",
        "outputId": "6a8e73ea-5211-4145-bdbc-30e63c952bb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "segmenter.tokenize(my_frame['jap'][1])"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start', '>', 'それ', 'が', 'ある', 'よう', 'にいつも', '思い', 'ます', '<', 'end', '>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kV5wBIO-XvCY"
      },
      "source": [
        "# This class creates a word -> index mapping (e.g,. \"dad\" -> 5) and vice-versa \n",
        "# (e.g., 5 -> \"dad\") for each language,\n",
        "class LanguageIndex():\n",
        "    def __init__(self, lang):\n",
        "        \"\"\" lang are the list of phrases from each language\"\"\"\n",
        "        self.lang = lang\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "        \n",
        "        self.create_index()\n",
        "        \n",
        "    def create_index(self):\n",
        "        for phrase in self.lang:\n",
        "            # update with individual tokens\n",
        "            self.vocab.update(phrase.split(' '))\n",
        "            \n",
        "        # sort the vocab\n",
        "        self.vocab = sorted(self.vocab)\n",
        "\n",
        "        # add a padding token with index 0\n",
        "        self.word2idx['<pad>'] = 0\n",
        "        \n",
        "        # word to index mapping\n",
        "        for index, word in enumerate(self.vocab):\n",
        "            self.word2idx[word] = index + 1 # +1 because of pad token\n",
        "        \n",
        "        # index to word mapping\n",
        "        for word, index in self.word2idx.items():\n",
        "            self.idx2word[index] = word      "
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2-_bGaTdEnn"
      },
      "source": [
        "# This class creates a word -> index mapping (e.g,. \"dad\" -> 5) and vice-versa \n",
        "# (e.g., 5 -> \"dad\") for each language,\n",
        "class JpLanguageIndex():\n",
        "    def __init__(self, lang):\n",
        "        \"\"\" lang are the list of phrases from each language\"\"\"\n",
        "        self.lang = lang\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "        \n",
        "        self.create_index()\n",
        "        \n",
        "    def create_index(self):\n",
        "        for phrase in self.lang:\n",
        "            # update with individual tokens\n",
        "            self.vocab.update(segmenter.tokenize(phrase))\n",
        "            \n",
        "        # sort the vocab\n",
        "        self.vocab = sorted(self.vocab)\n",
        "\n",
        "        # add a padding token with index 0\n",
        "        self.word2idx['<pad>'] = 0\n",
        "        \n",
        "        # word to index mapping\n",
        "        for index, word in enumerate(self.vocab):\n",
        "            self.word2idx[word] = index + 1 # +1 because of pad token\n",
        "        \n",
        "        # index to word mapping\n",
        "        for word, index in self.word2idx.items():\n",
        "            self.idx2word[index] = word  "
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Lo_edIlag13"
      },
      "source": [
        "['<start>'] + segmenter.tokenize(my_frame[\"jap\"][1]) + ['<end>'] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qq_0E_4ico1Q",
        "outputId": "60954e64-1ebe-46f8-e7ef-09cdeac52580"
      },
      "source": [
        "inp_lang.word2idx['word']"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7845"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIrsPpTYYFeh",
        "outputId": "fe81ab57-7bf4-495d-cb1b-e71f3f696cfe"
      },
      "source": [
        "# index language using the class above\n",
        "inp_lang = LanguageIndex(my_frame[\"eng\"].values.tolist())\n",
        "targ_lang = JpLanguageIndex(my_frame[\"jap\"].values.tolist())\n",
        "# Vectorize the input and target languages\n",
        "input_tensor = [[inp_lang.word2idx[s] for s in en.split(' ')]  for en in my_frame[\"eng\"].values.tolist()]\n",
        "target_tensor = [[targ_lang.word2idx[s] for s in ['<start>'] +  segmenter.tokenize(jap) + ['<end>']] for jap in my_frame[\"jap\"].values.tolist()]\n",
        "input_tensor[:10]"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[476, 1477, 7375, 1237, 8002, 1778, 5216],\n",
              " [493, 1477, 6512, 4721, 4501, 4493, 7365],\n",
              " [476, 4201, 3553, 4721, 7362, 4493, 7460, 5129],\n",
              " [476, 7375, 7338, 1242, 4493, 7344, 7583, 3349, 4727],\n",
              " [662, 7396, 7338, 8063],\n",
              " [768, 6512, 4721, 4502, 6070, 7477],\n",
              " [476, 7375, 1237, 4493, 4546, 1253, 4904, 5310, 7429],\n",
              " [476, 7375, 7338, 1237, 7910, 1792, 1489, 4496, 4330, 7344, 3822],\n",
              " [476, 7375, 7388, 7806, 4830, 1597, 7344, 1064, 1112],\n",
              " [476, 7375, 7388, 5122, 4493, 3778, 7344, 3119, 1172, 1112]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaiDMlrfYN-Z",
        "outputId": "f08033fd-4a55-4eac-fea4-73cf826ea26a"
      },
      "source": [
        "target_tensor[:10]"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 3, 4, 185, 56, 547, 509, 3648, 726, 1, 6, 3],\n",
              " [2, 3, 398, 185, 52, 823, 590, 3648, 726, 1, 6, 3],\n",
              " [2, 3, 398, 185, 2980, 549, 158, 506, 4540, 93, 1, 6, 3],\n",
              " [2,\n",
              "  3,\n",
              "  3306,\n",
              "  631,\n",
              "  764,\n",
              "  582,\n",
              "  3070,\n",
              "  841,\n",
              "  1184,\n",
              "  624,\n",
              "  1789,\n",
              "  448,\n",
              "  506,\n",
              "  3655,\n",
              "  1,\n",
              "  6,\n",
              "  3],\n",
              " [2, 3, 14, 506, 6114, 185, 3657, 412, 1, 6, 3],\n",
              " [2, 3, 4, 631, 325, 261, 448, 506, 3648, 726, 1, 6, 3],\n",
              " [2, 3, 4, 631, 4242, 624, 2775, 506, 3648, 726, 1, 6, 3],\n",
              " [2, 3, 4, 631, 1816, 624, 6117, 506, 3648, 726, 1, 6, 3],\n",
              " [2, 3, 398, 631, 4436, 4230, 2347, 624, 1970, 448, 506, 3648, 726, 1, 6, 3],\n",
              " [2, 3, 398, 631, 4222, 2307, 624, 4214, 448, 506, 3648, 726, 1, 6, 3]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5bD3ztjY8vU"
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPR5T4EWdl2o",
        "outputId": "2590d02b-2476-4b31-f0ad-1d9c83e7f314"
      },
      "source": [
        "# calculate the max_length of input and output tensor\n",
        "max_length_inp, max_length_tar = max_length(input_tensor), max_length(target_tensor)\n",
        "max_length_inp, max_length_tar"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT3aKecihz-S"
      },
      "source": [
        "def pad_sequences(x, max_len):\n",
        "    padded = np.zeros((max_len), dtype=np.int64)\n",
        "    if len(x) > max_len: padded[:] = x[:max_len]\n",
        "    else: padded[:len(x)] = x\n",
        "    \n",
        "    return padded"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGyBfFFKhS9p",
        "outputId": "1e19ea79-5006-4480-e856-95edcd632acd"
      },
      "source": [
        "# inplace padding\n",
        "input_tensor = [pad_sequences(x, max_length_inp) for x in input_tensor]\n",
        "target_tensor = [pad_sequences(x, max_length_tar) for x in target_tensor]\n",
        "\n",
        "len(input_tensor), len(target_tensor)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5303, 5303)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lufP-guTiVuM",
        "outputId": "f29f8efb-7503-4164-edd7-a4f2c0aa4a56"
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4242, 4242, 1061, 1061)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTMqxNN3ieby"
      },
      "source": [
        "# conver the data to tensors and pass to the Dataloader \n",
        "# to create an batch iterator\n",
        "\n",
        "class MyData(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.data = X\n",
        "        self.target = y\n",
        "        # TODO: convert this into torch code is possible\n",
        "        self.length = [ np.sum(1 - np.equal(x, 0)) for x in X]\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        x_len = self.length[index]\n",
        "        return x,y,x_len\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pn-MGvkgiqZR"
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word2idx)\n",
        "vocab_tar_size = len(targ_lang.word2idx)\n",
        "\n",
        "train_dataset = MyData(input_tensor_train, target_tensor_train)\n",
        "val_dataset = MyData(input_tensor_val, target_tensor_val)\n",
        "\n",
        "dataset = DataLoader(train_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cszx3o2ii0rg"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.gru = nn.GRU(self.embedding_dim, self.enc_units)\n",
        "        \n",
        "    def forward(self, x, lens, device):\n",
        "        # x: batch_size, max_length \n",
        "        \n",
        "        # x: batch_size, max_length, embedding_dim\n",
        "        x = self.embedding(x) \n",
        "                \n",
        "        # x transformed = max_len X batch_size X embedding_dim\n",
        "        # x = x.permute(1,0,2)\n",
        "        x = pack_padded_sequence(x, lens) # unpad\n",
        "    \n",
        "        self.hidden = self.initialize_hidden_state(device)\n",
        "        \n",
        "        # output: max_length, batch_size, enc_units\n",
        "        # self.hidden: 1, batch_size, enc_units\n",
        "        output, self.hidden = self.gru(x, self.hidden) # gru returns hidden state of all timesteps as well as hidden state at last timestep\n",
        "        \n",
        "        # pad the sequence to the max length in the batch\n",
        "        output, _ = pad_packed_sequence(output)\n",
        "        \n",
        "        return output, self.hidden\n",
        "\n",
        "    def initialize_hidden_state(self, device):\n",
        "        return torch.zeros((1, self.batch_sz, self.enc_units)).to(device)"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXDsrKGai4vw"
      },
      "source": [
        "### sort batch function to be able to use with pad_packed_sequence\n",
        "def sort_batch(X, y, lengths):\n",
        "    lengths, indx = lengths.sort(dim=0, descending=True)\n",
        "    X = X[indx]\n",
        "    y = y[indx]\n",
        "    return X.transpose(0,1), y, lengths # transpose (batch x seq) to (seq x batch)"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOisR121i7f5",
        "outputId": "f1cc6771-2546-4a43-918f-1d1cf06728ed"
      },
      "source": [
        "### Testing Encoder part\n",
        "# TODO: put whether GPU is available or not\n",
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "encoder.to(device)\n",
        "# obtain one sample from the data iterator\n",
        "it = iter(dataset)\n",
        "x, y, x_len = next(it)\n",
        "\n",
        "# sort the batch first to be able to use with pac_pack_sequence\n",
        "xs, ys, lens = sort_batch(x, y, x_len)\n",
        "\n",
        "enc_output, enc_hidden = encoder(xs.to(device), lens, device)\n",
        "\n",
        "print(enc_output.size()) # max_length, batch_size, enc_units"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 64, 1024])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjNOhoMai-0E"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, enc_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.enc_units = enc_units\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.gru = nn.GRU(self.embedding_dim + self.enc_units, \n",
        "                          self.dec_units,\n",
        "                          batch_first=True)\n",
        "        self.fc = nn.Linear(self.enc_units, self.vocab_size)\n",
        "        \n",
        "        # used for attention\n",
        "        self.W1 = nn.Linear(self.enc_units, self.dec_units)\n",
        "        self.W2 = nn.Linear(self.enc_units, self.dec_units)\n",
        "        self.V = nn.Linear(self.enc_units, 1)\n",
        "    \n",
        "    def forward(self, x, hidden, enc_output):\n",
        "        # enc_output original: (max_length, batch_size, enc_units)\n",
        "        # enc_output converted == (batch_size, max_length, hidden_size)\n",
        "        enc_output = enc_output.permute(1,0,2)\n",
        "        # hidden shape == (batch_size, hidden size)\n",
        "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "        # we are doing this to perform addition to calculate the score\n",
        "        \n",
        "        # hidden shape == (batch_size, hidden size)\n",
        "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "        hidden_with_time_axis = hidden.permute(1, 0, 2)\n",
        "        \n",
        "        # score: (batch_size, max_length, hidden_size) # Bahdanaus's\n",
        "        # we get 1 at the last axis because we are applying tanh(FC(EO) + FC(H)) to self.V\n",
        "        # It doesn't matter which FC we pick for each of the inputs\n",
        "        score = torch.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis))\n",
        "        \n",
        "        #score = torch.tanh(self.W2(hidden_with_time_axis) + self.W1(enc_output))\n",
        "          \n",
        "        # attention_weights shape == (batch_size, max_length, 1)\n",
        "        # we get 1 at the last axis because we are applying score to self.V\n",
        "        attention_weights = torch.softmax(self.V(score), dim=1)\n",
        "        \n",
        "        # context_vector shape after sum == (batch_size, hidden_size)\n",
        "        context_vector = attention_weights * enc_output\n",
        "        context_vector = torch.sum(context_vector, dim=1)\n",
        "        \n",
        "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "        # takes case of the right portion of the model above (illustrated in red)\n",
        "        x = self.embedding(x)\n",
        "        \n",
        "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "        #x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        # ? Looks like attention vector in diagram of source\n",
        "        x = torch.cat((context_vector.unsqueeze(1), x), -1)\n",
        "        \n",
        "        # passing the concatenated vector to the GRU\n",
        "        # output: (batch_size, 1, hidden_size)\n",
        "        output, state = self.gru(x)\n",
        "        \n",
        "        \n",
        "        # output shape == (batch_size * 1, hidden_size)\n",
        "        output =  output.view(-1, output.size(2))\n",
        "        \n",
        "        # output shape == (batch_size * 1, vocab)\n",
        "        x = self.fc(output)\n",
        "        \n",
        "        return x, state, attention_weights\n",
        "    \n",
        "    def initialize_hidden_state(self):\n",
        "        return torch.zeros((1, self.batch_sz, self.dec_units))"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "401vCjfDjdT4",
        "outputId": "3e234ed5-556c-43ad-ff07-f07f3c6d91b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "encoder.to(device)\n",
        "# obtain one sample from the data iterator\n",
        "it = iter(dataset)\n",
        "x, y, x_len = next(it)\n",
        "\n",
        "print(\"Input: \", x.shape)\n",
        "print(\"Output: \", y.shape)\n",
        "\n",
        "# sort the batch first to be able to use with pac_pack_sequence\n",
        "xs, ys, lens = sort_batch(x, y, x_len)\n",
        "\n",
        "enc_output, enc_hidden = encoder(xs.to(device), lens, device)\n",
        "print(\"Encoder Output: \", enc_output.shape) # batch_size X max_length X enc_units\n",
        "print(\"Encoder Hidden: \", enc_hidden.shape) # batch_size X enc_units (corresponds to the last state)\n",
        "\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, units, BATCH_SIZE)\n",
        "decoder = decoder.to(device)\n",
        "\n",
        "#print(enc_hidden.squeeze(0).shape)\n",
        "\n",
        "dec_hidden = enc_hidden#.squeeze(0)\n",
        "dec_input = torch.tensor([[targ_lang.word2idx['<start>']]] * BATCH_SIZE)\n",
        "print(\"Decoder Input: \", dec_input.shape)\n",
        "print(\"--------\")\n",
        "\n",
        "for t in range(1, y.size(1)):\n",
        "    # enc_hidden: 1, batch_size, enc_units\n",
        "    # output: max_length, batch_size, enc_units\n",
        "    predictions, dec_hidden, _ = decoder(dec_input.to(device), \n",
        "                                         dec_hidden.to(device), \n",
        "                                         enc_output.to(device))\n",
        "    \n",
        "    print(\"Prediction: \", predictions.shape)\n",
        "    print(\"Decoder Hidden: \", dec_hidden.shape)\n",
        "    \n",
        "    #loss += loss_function(y[:, t].to(device), predictions.to(device))\n",
        "    \n",
        "    dec_input = y[:, t].unsqueeze(1)\n",
        "    print(dec_input.shape)\n",
        "    breaks += loss_function(y[:, t].to(device), predictions.to(device))\n",
        "    \n",
        "    dec_input = y[:, t].unsqueeze(1)\n",
        "    print(dec_input.shape)\n",
        "    break"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:  torch.Size([64, 28])\n",
            "Output:  torch.Size([64, 32])\n",
            "Encoder Output:  torch.Size([18, 64, 1024])\n",
            "Encoder Hidden:  torch.Size([1, 64, 1024])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-122-557b9a02c7f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mdec_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[0;31m#.squeeze(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mdec_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarg_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<start>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Decoder Input: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '<start>'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ybv7dt_ojmJr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}