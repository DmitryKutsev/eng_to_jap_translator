{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled47.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO67E8RO4R93clIJAYJpl04",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DmitryKutsev/eng_to_jap_translator/blob/main/seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ytt4JlBZO3M",
        "outputId": "28cd7008-45cd-41e7-a0f9-1774c7440200"
      },
      "source": [
        "!pip install tinysegmenter"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tinysegmenter\n",
            "  Downloading https://files.pythonhosted.org/packages/9c/70/488895cb11e160b548c9ba5847c171b65b86a8ca1e54d206d55b2976bf7b/tinysegmenter-0.4.tar.gz\n",
            "Building wheels for collected packages: tinysegmenter\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.4-cp36-none-any.whl size=13536 sha256=b8ed9f37cf1595d1ab024521cf69dc49f1c710217f510bb516bdd792da2da9b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/71/2b/6402196bf28012826e507ef7b99df6ebd98cce78bd99023471\n",
            "Successfully built tinysegmenter\n",
            "Installing collected packages: tinysegmenter\n",
            "Successfully installed tinysegmenter-0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3F_2aqNlVxoX"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torchtext\n",
        "from torchtext.data import Field, BucketIterator, TabularDataset\n",
        "import random\n",
        "import spacy\n",
        "import tinysegmenter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNLjawCzuJXU"
      },
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI3u2k5TuXBb"
      },
      "source": [
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ1Np6TNtVY9"
      },
      "source": [
        "spacy_en = spacy.load('en')"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-t9olLUZ11J"
      },
      "source": [
        "segmenter = tinysegmenter.TinySegmenter()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-CSyftcWATc"
      },
      "source": [
        "my_frame = pd.read_excel(\n",
        "'http://nlp.ist.i.kyoto-u.ac.jp/EN/?plugin=attach&refer=JEC%20Basic%20Sentence%20Data&openfile=JEC_basic_sentence_v1-2.xls')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7vAkhV_XVgK"
      },
      "source": [
        "#remove Chineese column\n",
        "my_frame = my_frame.drop(['难道不会是X吗，我实在是感到怀疑。'], axis=1)\n",
        "my_frame.columns = ['index', 'jp', 'en']\n",
        "my_frame = my_frame.drop(['index'], axis=1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOfXTtcClM7_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "cf98064b-8307-424c-d4d4-2abe9429cf6d"
      },
      "source": [
        "my_frame"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>jp</th>\n",
              "      <th>en</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Xがいいなといつも思います</td>\n",
              "      <td>I always think X would be nice.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>それがあるようにいつも思います</td>\n",
              "      <td>It always seems like it is there.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>それが多すぎないかと正直思う</td>\n",
              "      <td>I honestly feel like there is too much.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>山田はみんなに好かれるタイプの人だと思う</td>\n",
              "      <td>I think that Yamada is the type everybody likes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>〜と誰かが思った</td>\n",
              "      <td>Someone thought that 〜</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5298</th>\n",
              "      <td>チームが４人のメンバーで構成されています</td>\n",
              "      <td>The team consists of four members.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5299</th>\n",
              "      <td>彼が実際に動画を再生する</td>\n",
              "      <td>He actually plays the video.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5300</th>\n",
              "      <td>政府が銀行に公的資金をどんどん投入しました</td>\n",
              "      <td>The government injected massive public funds i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5301</th>\n",
              "      <td>レベル１の機能に下記の機能をプラスする</td>\n",
              "      <td>The following will be added to the level 1 fun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5302</th>\n",
              "      <td>彼が携帯を制服のポケットに仕舞う</td>\n",
              "      <td>He puts his cell phone into the pocket of his ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5303 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                         jp                                                 en\n",
              "0             Xがいいなといつも思います                    I always think X would be nice.\n",
              "1           それがあるようにいつも思います                  It always seems like it is there.\n",
              "2            それが多すぎないかと正直思う            I honestly feel like there is too much.\n",
              "3      山田はみんなに好かれるタイプの人だと思う   I think that Yamada is the type everybody likes.\n",
              "4                  〜と誰かが思った                             Someone thought that 〜\n",
              "...                     ...                                                ...\n",
              "5298   チームが４人のメンバーで構成されています                 The team consists of four members.\n",
              "5299           彼が実際に動画を再生する                       He actually plays the video.\n",
              "5300  政府が銀行に公的資金をどんどん投入しました  The government injected massive public funds i...\n",
              "5301    レベル１の機能に下記の機能をプラスする  The following will be added to the level 1 fun...\n",
              "5302       彼が携帯を制服のポケットに仕舞う  He puts his cell phone into the pocket of his ...\n",
              "\n",
              "[5303 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "867hWid-lsCx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bb8ddac-949a-4fd8-8b3f-6c028e46c8ff"
      },
      "source": [
        "segmenter.tokenize(my_frame['jp'][1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['それ', 'が', 'ある', 'よう', 'にいつも', '思い', 'ます']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZsQH33qt4Sf",
        "outputId": "b6339b56-1368-4f86-b25d-2ecff65c9e38"
      },
      "source": [
        "[tok.text for tok in spacy_en.tokenizer(my_frame['en'][1])]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['It', 'always', 'seems', 'like', 'it', 'is', 'there', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiMWnSpXt4Yc"
      },
      "source": [
        "my_frame.to_csv('my_frame.csv', index=False)  "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWCcevdZtYCj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee1b2641-0308-415c-eba4-0619a436e254"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my_frame.csv  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxFeNV_JI2OG",
        "outputId": "08f3490a-4acd-4192-b3b8-d32d8be641c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "textt = ';iaoj2q09r<sos>'\n",
        "if '<sos>' in textt:\n",
        "  textt = textt.replace('<sos>',' ')\n",
        "textt"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "';iaoj2q09r '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KD5qDjYJG-X",
        "outputId": "18336f0b-557a-485c-ce70-7a7e8eb8a53a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "'<sos>' in textt"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZu4XaC6u2ON"
      },
      "source": [
        "def tokenize_jp(text):\n",
        "    \"\"\"\n",
        "    Tokenizes JP text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    my_sos = None\n",
        "    my_eos = None\n",
        "    if '<sos>' in text:\n",
        "      text = text.replace('<sos>','')\n",
        "      my_sos = True\n",
        "    if '<eos>' in text:\n",
        "      text = text.replace('<eos>','')\n",
        "      my_eos = True\n",
        "    if my_sos == True and my_eos == True:\n",
        "      return ['<sos>'] + segmenter.tokenize(text) + ['<eos>']\n",
        "    elif my_sos == True:\n",
        "      return ['<sos>'] + segmenter.tokenize(text)\n",
        "    elif my_eos == True:\n",
        "      return segmenter.tokenize(text) + ['<eos>']\n",
        "    else:\n",
        "      return segmenter.tokenize(text)\n",
        "\n",
        "\n",
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBmfATqXvEdh"
      },
      "source": [
        "SRC = Field(tokenize=tokenize_en, init_token='<sos>', eos_token='<eos>')\n",
        "TRG = Field(tokenize=tokenize_jp, init_token='<sos>', eos_token='<eos>')"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUDjF--svKCa"
      },
      "source": [
        "dataset = TabularDataset(path='my_frame.csv', \n",
        "                         format='csv', \n",
        "                         fields=[ ('jp', TRG), ('en', SRC),],\n",
        "                         skip_header=True)"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb_ZTRXCvXvT"
      },
      "source": [
        "train_data, valid_data, test_data = dataset.split(split_ratio=[0.7, 0.1, 0.2], \n",
        "                                            random_state=random.getstate())"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyWpxXrivcFQ"
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq=2)\n",
        "TRG.build_vocab(train_data, min_freq=2)"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MAiAqTUA7nN",
        "outputId": "44297cd9-a729-4fcb-9a34-de83b804a725"
      },
      "source": [
        "print(vars(train_data.examples[0])['en'])"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['You', 'can', 'enjoy', 'fishing', 'each', 'season', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmJTfi3NveB3",
        "outputId": "b18262fc-61bf-4991-cae6-118e5fcc088c"
      },
      "source": [
        "print (len(SRC.vocab), len(TRG.vocab))\n",
        "print (SRC.vocab.freqs.most_common(10))\n",
        "print (TRG.vocab.freqs.most_common(10))"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2378 2351\n",
            "[('.', 3466), ('the', 1631), ('He', 886), ('to', 641), ('of', 640), ('a', 632), ('in', 543), ('The', 513), ('I', 464), ('will', 437)]\n",
            "[('が', 2842), ('の', 2451), ('を', 2371), ('に', 2005), ('た', 1075), ('ます', 1063), ('彼', 934), ('は', 668), ('し', 656), ('、', 532)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqftPA1QxRL2"
      },
      "source": [
        "# gpu = False\n",
        "# device = torch.device('cuda' if gpu and torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfcvmRLPvh7J"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "     batch_size = BATCH_SIZE,\n",
        "     sort_key=lambda x: len(x.jp), \n",
        "     sort_within_batch=False,\n",
        "     device = device)\n"
      ],
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4ijkRfBLlfE"
      },
      "source": [
        "\n",
        "# for b in valid_iterator:\n",
        "#     print (b.jp, b.en)\n",
        "#     sys.exit()\n"
      ],
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIUixh0j_4I7",
        "outputId": "822113f1-07dd-446c-fbcf-d2fb0c6de696"
      },
      "source": [
        "print(vars(valid_iterator))"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 128, 'train': False, 'dataset': <torchtext.data.dataset.Dataset object at 0x7ff8f1527e80>, 'batch_size_fn': None, 'iterations': 1, 'repeat': False, 'shuffle': False, 'sort': True, 'sort_within_batch': False, 'sort_key': <function <lambda> at 0x7ff8f4f9be18>, 'device': device(type='cpu'), 'random_shuffler': <torchtext.data.utils.RandomShuffler object at 0x7ff8f1a68160>, '_iterations_this_epoch': 1, '_random_state_this_epoch': (3, (3297715018, 58426169, 253714516, 2099196304, 3733172384, 4212010110, 2783653618, 1768284441, 4209158285, 744410686, 2103605509, 2842406700, 2289981335, 212922146, 2778221656, 1053740017, 1424792856, 4224842428, 3731841819, 2988451423, 627018369, 1607112236, 3657240987, 2038364475, 1298114200, 2120695671, 284817816, 3883902282, 2896043057, 1831934767, 39630914, 1666895466, 548679849, 117588422, 767399583, 196252336, 1245245934, 760930545, 2918238418, 413140758, 2875319190, 372672283, 3724087970, 68702924, 899383256, 3368677049, 3601359505, 2287426719, 2739605683, 1502517508, 3555038002, 2528530076, 1613529082, 3898891079, 927510897, 864376401, 3723605207, 3885494757, 1260020850, 1562218300, 395756863, 2703475791, 4190020942, 1354002809, 3632500244, 1694614628, 810050461, 3418963582, 212010087, 3245601205, 2329649734, 3397591975, 3937593072, 3525285198, 913996882, 3377143466, 2203184853, 670064064, 3155095752, 2348188035, 1124244045, 1283856839, 2840584613, 722927702, 2512757265, 1733651972, 1161317908, 3756256901, 621000644, 3504521770, 4100394836, 1355025864, 906021524, 1462982273, 3870368829, 261157888, 1852016965, 2387484712, 1095732659, 86361123, 767116001, 307259026, 2841481404, 2369792609, 3979263067, 3592215100, 273997428, 507754861, 3770290114, 1720881597, 941700263, 940966832, 2038998088, 895910703, 2593653609, 1447902347, 3738750363, 1362925180, 2310963732, 1710982710, 1252467481, 3311004348, 395112670, 3611912639, 4184365661, 757525035, 1272074570, 1435661848, 3787980207, 1140067966, 3946193307, 407823632, 1628713557, 1540037627, 1448607703, 731476355, 4188311068, 4259091098, 659848068, 2889972828, 2343927180, 2560460109, 2138058215, 949481400, 4011112785, 1613472839, 273405126, 2025547712, 379546856, 1748382742, 4176577365, 709204883, 2663078329, 1932710007, 38700776, 2855247312, 478743451, 832474747, 3087529415, 2324724086, 2128463063, 937399246, 1345502569, 3840333882, 3600335840, 13270137, 3890126297, 1924465881, 2610770840, 3191916608, 678547235, 3000532457, 744187286, 1962005549, 3467601556, 873033647, 2864331580, 1846301656, 3144863195, 1538232634, 253992024, 3120594853, 3179843071, 3007140212, 2722949229, 3392647082, 3517172274, 3089423401, 2179007856, 3782627361, 854110528, 3625008345, 301286528, 925238777, 2603907278, 299751402, 1993923839, 1034430044, 3120331853, 1823334231, 1607814230, 502278564, 3565481572, 2446293557, 1487403471, 1501888150, 1342062000, 3307031674, 1032179173, 795710348, 2448240304, 2989671196, 2711637318, 2704097014, 2089100159, 2405448009, 1029117723, 1962891370, 4269418082, 1003527559, 794224450, 3225113034, 1132420747, 582480265, 1000512658, 954492318, 613680008, 2468003367, 3512185144, 769966336, 1826929981, 2488880689, 303750168, 2019001642, 3955305792, 1600612257, 590211166, 3779864418, 3497528007, 874470445, 978427348, 489244923, 1337288095, 2246846334, 3921219470, 2678219460, 427466973, 2552105111, 1040919509, 2742765203, 1610259063, 2218440880, 2163547148, 4166962649, 3620167159, 3761522139, 3817402819, 2854364924, 2343067961, 2128495605, 2529416005, 3546090248, 659438188, 1667455632, 389820436, 126337675, 3402271289, 3599290885, 1960088558, 3595321178, 2663472042, 684949527, 4118958255, 4042565012, 1229584687, 3071484516, 493701909, 1949367907, 1860886967, 1873905269, 4127422951, 3913894823, 3815217301, 3433140578, 15026705, 1194878319, 1091977780, 1726853912, 669749812, 745593606, 954762680, 2857128356, 1215726846, 3715929992, 1010515032, 1773276735, 1086368015, 2270388727, 1209261640, 4035353146, 1362380028, 3497952112, 1117756316, 3847870824, 681734216, 1163002642, 1676709986, 849912424, 2767326927, 932763737, 32034036, 495075967, 4090138548, 2092421406, 2848498490, 2078507606, 1857037252, 1290916548, 2783598758, 2985751348, 3215037877, 477134298, 2701398644, 3071139709, 3658645754, 3017217760, 4115236016, 2053620261, 2646109078, 2688181626, 2890973078, 3597119107, 192940128, 2993230915, 4019425626, 1096538890, 218824036, 2724104334, 3706425491, 2586986162, 3702772649, 198080579, 3116545638, 4270945361, 2084122167, 833123708, 628559913, 4157642321, 2350444913, 3028967368, 3342266510, 119113578, 1760487261, 2992334826, 2282119556, 853711056, 413277641, 2429497370, 1155746897, 2903369159, 2772265897, 2374863446, 1828500657, 3592087718, 3209832531, 845729112, 1876373805, 3717787091, 3925561739, 2756401284, 2106589103, 359753737, 1599715654, 1843008134, 217008952, 4189789196, 3888882083, 3287614126, 1608307616, 2775079223, 2926254184, 3450730060, 900772947, 1078986288, 489169604, 285322182, 3025487553, 1887327186, 226304162, 2319022630, 2742260980, 3718438188, 4108848661, 3719902099, 4147716296, 2676390002, 3299040310, 1548798580, 3033080887, 600207864, 3236048518, 4231406088, 1944592851, 3031357453, 600076187, 1170046413, 108181559, 1303467781, 1139332633, 3888687050, 371261892, 3769814942, 2902165060, 3847014015, 3178781075, 1394734550, 2176408759, 3090625572, 4040807939, 3328046358, 644630208, 3063914517, 3935580597, 489032225, 192122864, 2437443082, 713613400, 2383445068, 557374167, 4255895242, 1841962872, 2912865163, 452726161, 1089855489, 3572896968, 1650978985, 3694071388, 4190439585, 4233481842, 2407973624, 1230164122, 1124325370, 65908795, 751051369, 3574275276, 728089378, 1177052837, 1196815478, 1839777262, 2202220459, 2990184288, 3642432554, 2419660984, 1593616831, 2564164969, 2710258698, 95638990, 3190540379, 2988364366, 2321530707, 3552479527, 2442100353, 920657926, 106511302, 1054742220, 3401927909, 1694215585, 24021288, 1083386572, 4163778105, 1414258593, 1061339601, 3617667938, 3980882064, 293670546, 2859151098, 1794373251, 3932574752, 3051061504, 3103238543, 3651595821, 3469059294, 395135344, 2116521385, 1641798483, 551914578, 878449096, 3420452117, 4066433996, 1586111593, 1219628278, 1387236811, 3298916054, 241845099, 210970549, 454635330, 53472838, 2803747866, 4238303590, 3907730583, 698655925, 3337539819, 3106483641, 3023620240, 1360202521, 1024219563, 770618258, 53119928, 3381717063, 3912704731, 345169095, 163063199, 151292221, 1874282717, 4098932491, 2648521633, 3980252471, 3473215065, 1022613411, 622625438, 2964454838, 842830773, 1624456851, 1527757370, 4233959178, 2906819578, 1371776862, 1120132270, 1860085426, 2091590271, 459167172, 2094259556, 1338472509, 1206674722, 2753321116, 1636932280, 1756692689, 2831203613, 3133243413, 2230896286, 3770221564, 3126419334, 4011421384, 1342355807, 1573478224, 2801062564, 2104402489, 3203769721, 1864290390, 837503071, 2701769932, 596949218, 1828860316, 3030118858, 3464177567, 3200601940, 2369861975, 1656948126, 3810232236, 4232803776, 3184365035, 2478712600, 2567606620, 2214619219, 4044317296, 1797583478, 3735577689, 637610137, 983512848, 132245853, 2561561156, 3959826669, 3894623852, 3739948219, 2470234487, 271909564, 1992472924, 3845127551, 76742160, 782657803, 1970131393, 3416511799, 3880840166, 1599323911, 2580768386, 951978007, 2775872746, 260597587, 2043690037, 1306298794, 3450798166, 2099133851, 3568315481, 3482267927, 3352608725, 3144141307, 2199394627, 3079702343, 3890282884, 579503088, 4088590428, 1643575530, 925426099, 3192875751, 1914703942, 2844709271, 2399870624, 4181558988, 1930829214, 1741270606, 1866288538, 342555087, 2319612848, 1106473140, 3285888887, 3557922092, 2873678863, 2203882790, 62201135, 3659515981, 3545032374, 2672833208, 3415290703, 3873754515, 28), None), '_restored_from_state': False, 'batches': <generator object batch at 0x7ff8f50779e8>}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2KERuieLSKp",
        "outputId": "d0ed4155-e8d2-4b17-c45d-20f685a17c29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(valid_iterator))"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUIsuJTMxazl"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        \n",
        "        #embedded = [src len, batch size, emb dim]\n",
        "        \n",
        "        outputs, (hidden, cell) = self.rnn(embedded)\n",
        "        \n",
        "        #outputs  = [src len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #outputs are always from the top hidden layer\n",
        "        \n",
        "        return hidden, cell"
      ],
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f1KFSFe755Z"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.output_dim = output_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden, cell):\n",
        "        \n",
        "        #input = [batch size]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #n directions in the decoder will both always be 1, therefore:\n",
        "        #hidden = [n layers, batch size, hid dim]\n",
        "        #context = [n layers, batch size, hid dim]\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "        \n",
        "        #input = [1, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        \n",
        "        #embedded = [1, batch size, emb dim]\n",
        "                \n",
        "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
        "        \n",
        "        #output = [seq len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #seq len and n directions will always be 1 in the decoder, therefore:\n",
        "        #output = [1, batch size, hid dim]\n",
        "        #hidden = [n layers, batch size, hid dim]\n",
        "        #cell = [n layers, batch size, hid dim]\n",
        "        \n",
        "        prediction = self.fc_out(output.squeeze(0))\n",
        "        \n",
        "        #prediction = [batch size, output dim]\n",
        "        \n",
        "        return prediction, hidden, cell"
      ],
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62ouCUie7-Yq"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        \n",
        "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
        "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        assert encoder.n_layers == decoder.n_layers, \\\n",
        "            \"Encoder and decoder must have equal number of layers!\"\n",
        "        \n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        #trg = [trg len, batch size]\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
        "        \n",
        "        batch_size = trg.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        # 128(batch_size)个例子, 每个例子里的句子长度为32(trg_len), 每个句子里的单词都有5893维(vacab_size)\n",
        "\n",
        "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
        "        hidden, cell = self.encoder(src)\n",
        "        \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input = trg[0,:]\n",
        "        \n",
        "        for t in range(1, trg_len):\n",
        "            \n",
        "            #insert input token embedding, previous hidden and previous cell states\n",
        "            #receive output tensor (predictions) and new hidden and cell states\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "            \n",
        "            #place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "            \n",
        "            #decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            \n",
        "            #get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1) \n",
        "            \n",
        "            #if teacher forcing, use actual next token as next input\n",
        "            #if not, use predicted token\n",
        "            input = trg[t] if teacher_force else top1\n",
        "        \n",
        "        return outputs"
      ],
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8DFIOPOBiWh",
        "outputId": "e44f9560-58c1-46a7-c550-821dcf9d2e29"
      },
      "source": [
        "len(SRC.vocab), len(TRG.vocab)"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2378, 2351)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhRW4pSI8B33"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab) # 7855\n",
        "OUTPUT_DIM = len(TRG.vocab) # 5893\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.3\n",
        "DEC_DROPOUT = 0.3\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ],
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnWCIOb28Eca",
        "outputId": "80c61da9-5b5f-4468-bd26-9516716f9890"
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "        \n",
        "model.apply(init_weights)"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(2378, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.3)\n",
              "    (dropout): Dropout(p=0.3, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(2351, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.3)\n",
              "    (fc_out): Linear(in_features=512, out_features=2351, bias=True)\n",
              "    (dropout): Dropout(p=0.3, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJ9yJdDi8HQk",
        "outputId": "5d7d78a3-11bd-45c6-b6c4-a13dd0b9b370"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 9,773,103 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NostO82q8KUa",
        "outputId": "29f42f95-10de-4fe8-8d72-a723d10915ea"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "pad_idx = TRG.vocab.stoi['<pad>']\n",
        "print(TRG.pad_token)  # <pad>\n",
        "print(TRG.vocab.stoi[TRG.pad_token]) # 1 \n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<pad>\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pTg8V6z8MXF",
        "outputId": "5f25d861-53de-4fc2-db48-9c93f791ab8b"
      },
      "source": [
        "epoch_loss = 0\n",
        "for i, batch in enumerate(train_iterator):\n",
        "  # print(i,batch)\n",
        "  src = batch.en\n",
        "  trg = batch.jp\n",
        "    \n",
        "  output = model(src, trg)\n",
        "  output_dim = output.shape[-1]  # 5893\n",
        "\n",
        "  new_output = output[1:].view(-1, output_dim)  # remove <sos>, [out len * batchsize, output dim]\n",
        "  new_trg = trg[1:].view(-1)  # remove <sos> , [trg len * batchsize]\n",
        "    \n",
        "  loss = criterion(new_output, new_trg)\n",
        "  epoch_loss += loss.item()\n",
        "print(epoch_loss / len(train_iterator)) # 3.0412618011104904"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7.760480124374916\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJ41zk0j8ZL8"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src = batch.en\n",
        "        trg = batch.jp\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(src, trg)\n",
        "        \n",
        "        #trg = [trg len, batch size]\n",
        "        #output = [trg len, batch size, output dim]\n",
        "        \n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "        \n",
        "        #trg = [(trg len - 1) * batch size]\n",
        "        #output = [(trg len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vo20BXfSF4lg"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.en\n",
        "            trg = batch.jp\n",
        "\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            #trg = [trg len, batch size]\n",
        "            #output = [trg len, batch size, output dim]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            #trg = [(trg len - 1) * batch size]\n",
        "            #output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35jnuevHF6zH"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaoXwxnfF8xF",
        "outputId": "4d5e8c3a-e65e-41ff-cf89-bca930425d86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "N_EPOCHS = 2\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 1m 49s\n",
            "\tTrain Loss: 4.733 | Train PPL: 113.639\n",
            "\t Val. Loss: 4.402 |  Val. PPL:  81.600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgzIR2XuGWl5"
      },
      "source": [
        "def translate_sentence(sentence,src_field,trg_field,model,device, max_len=50):\n",
        "    model.eval()\n",
        "\n",
        "    if isinstance(sentence,str):\n",
        "        nlp = spacy.load('de')\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "\n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        hidden, cell = model.encoder(src_tensor)\n",
        "\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    #\n",
        "    for i in range(max_len):\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, hidden, cell = model.decoder(trg_tensor, hidden, cell)\n",
        "        pred_token = output.argmax(1).item()\n",
        "        trg_indexes.append(pred_token)\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "\n",
        "    return trg_tokens[1:-1] # remove <sos> and <eos>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpfGOIOHJqfW"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "model_save_name = 'tut1-model.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmsywaiOGZk9"
      },
      "source": [
        "example_idx = 12\n",
        "\n",
        "src = vars(train_data.examples[example_idx])['en']\n",
        "trg = vars(train_data.examples[example_idx])['jp]\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')\n",
        "\n",
        "translation = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPHhrTR3GkJe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}