{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled47.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN0fyYI0QHh3HaBLU7uXOar",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DmitryKutsev/eng_to_jap_translator/blob/main/seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ytt4JlBZO3M",
        "outputId": "00a4f41a-ee4e-4b03-a0eb-3f925778b249"
      },
      "source": [
        "!pip install tinysegmenter"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tinysegmenter in /usr/local/lib/python3.6/dist-packages (0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3F_2aqNlVxoX"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torchtext\n",
        "from torchtext.data import Field, BucketIterator, TabularDataset\n",
        "import random\n",
        "import spacy\n",
        "import tinysegmenter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNLjawCzuJXU"
      },
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI3u2k5TuXBb"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ1Np6TNtVY9"
      },
      "source": [
        "spacy_en = spacy.load('en')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-t9olLUZ11J"
      },
      "source": [
        "segmenter = tinysegmenter.TinySegmenter()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-CSyftcWATc"
      },
      "source": [
        "my_frame = pd.read_excel(\n",
        "'http://nlp.ist.i.kyoto-u.ac.jp/EN/?plugin=attach&refer=JEC%20Basic%20Sentence%20Data&openfile=JEC_basic_sentence_v1-2.xls')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7vAkhV_XVgK"
      },
      "source": [
        "#remove Chineese column\n",
        "my_frame = my_frame.drop(['难道不会是X吗，我实在是感到怀疑。'], axis=1)\n",
        "my_frame.columns = ['index', 'jp', 'en']\n",
        "my_frame = my_frame.drop(['index'], axis=1)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOfXTtcClM7_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "78ca4504-9e07-4872-d9a7-ab6541bd855d"
      },
      "source": [
        "my_frame"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>jp</th>\n",
              "      <th>en</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Xがいいなといつも思います</td>\n",
              "      <td>I always think X would be nice.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>それがあるようにいつも思います</td>\n",
              "      <td>It always seems like it is there.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>それが多すぎないかと正直思う</td>\n",
              "      <td>I honestly feel like there is too much.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>山田はみんなに好かれるタイプの人だと思う</td>\n",
              "      <td>I think that Yamada is the type everybody likes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>〜と誰かが思った</td>\n",
              "      <td>Someone thought that 〜</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5298</th>\n",
              "      <td>チームが４人のメンバーで構成されています</td>\n",
              "      <td>The team consists of four members.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5299</th>\n",
              "      <td>彼が実際に動画を再生する</td>\n",
              "      <td>He actually plays the video.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5300</th>\n",
              "      <td>政府が銀行に公的資金をどんどん投入しました</td>\n",
              "      <td>The government injected massive public funds i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5301</th>\n",
              "      <td>レベル１の機能に下記の機能をプラスする</td>\n",
              "      <td>The following will be added to the level 1 fun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5302</th>\n",
              "      <td>彼が携帯を制服のポケットに仕舞う</td>\n",
              "      <td>He puts his cell phone into the pocket of his ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5303 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                         jp                                                 en\n",
              "0             Xがいいなといつも思います                    I always think X would be nice.\n",
              "1           それがあるようにいつも思います                  It always seems like it is there.\n",
              "2            それが多すぎないかと正直思う            I honestly feel like there is too much.\n",
              "3      山田はみんなに好かれるタイプの人だと思う   I think that Yamada is the type everybody likes.\n",
              "4                  〜と誰かが思った                             Someone thought that 〜\n",
              "...                     ...                                                ...\n",
              "5298   チームが４人のメンバーで構成されています                 The team consists of four members.\n",
              "5299           彼が実際に動画を再生する                       He actually plays the video.\n",
              "5300  政府が銀行に公的資金をどんどん投入しました  The government injected massive public funds i...\n",
              "5301    レベル１の機能に下記の機能をプラスする  The following will be added to the level 1 fun...\n",
              "5302       彼が携帯を制服のポケットに仕舞う  He puts his cell phone into the pocket of his ...\n",
              "\n",
              "[5303 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "867hWid-lsCx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7fdde3c-3be8-4fd3-b975-eeffd829b765"
      },
      "source": [
        "segmenter.tokenize(my_frame['jp'][1])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['それ', 'が', 'ある', 'よう', 'にいつも', '思い', 'ます']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZsQH33qt4Sf",
        "outputId": "1355e8d3-ae92-47cd-ee13-7cee453dbab0"
      },
      "source": [
        "[tok.text for tok in spacy_en.tokenizer(my_frame['en'][1])]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['It', 'always', 'seems', 'like', 'it', 'is', 'there', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiMWnSpXt4Yc"
      },
      "source": [
        "my_frame.to_csv('my_frame.csv', index=False)  "
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWCcevdZtYCj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f12c2cb-49b1-4d1e-e91b-78df8ca253fd"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my_frame.csv  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZu4XaC6u2ON"
      },
      "source": [
        "def tokenize_jp(text):\n",
        "    \"\"\"\n",
        "    Tokenizes JP text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    return segmenter.tokenize(text)\n",
        "\n",
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBmfATqXvEdh"
      },
      "source": [
        "SRC = Field(tokenize=tokenize_jp, init_token='<sos>', eos_token='<eos>')\n",
        "TRG = Field(tokenize=tokenize_en, init_token='<sos>', eos_token='<eos>')"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUDjF--svKCa"
      },
      "source": [
        "dataset = TabularDataset(path='my_frame.csv', \n",
        "                         format='csv', \n",
        "                         fields=[('en', SRC), ('jp', TRG)],\n",
        "                         skip_header=True)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb_ZTRXCvXvT"
      },
      "source": [
        "train_dt, valid_dt, test_dt = dataset.split(split_ratio=[0.7, 0.1, 0.2], \n",
        "                                            random_state=random.getstate())"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyWpxXrivcFQ"
      },
      "source": [
        "SRC.build_vocab(train_dt, min_freq=2)\n",
        "TRG.build_vocab(train_dt, min_freq=2)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmJTfi3NveB3",
        "outputId": "1ac50545-3814-44e2-fcca-e87f1f63d792"
      },
      "source": [
        "print (len(SRC.vocab), len(TRG.vocab))\n",
        "print (SRC.vocab.freqs.most_common(10))\n",
        "print (TRG.vocab.freqs.most_common(10))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2399 2406\n",
            "[('が', 2865), ('の', 2473), ('を', 2320), ('に', 2011), ('ます', 1082), ('た', 1079), ('彼', 927), ('し', 680), ('は', 668), ('、', 524)]\n",
            "[('.', 3477), ('the', 1641), ('He', 872), ('of', 648), ('to', 628), ('a', 615), ('in', 535), ('The', 498), ('I', 485), ('will', 435)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfcvmRLPvh7J"
      },
      "source": [
        "batch_size = 32\n",
        "train_it, valid_it, test_it = BucketIterator.splits((train_dt, valid_dt, test_dt),\n",
        "                                                    batch_size=batch_size, \n",
        "                                                    sort_key=lambda x: len(x.jp), \n",
        "                                                    sort_within_batch=False, \n",
        "                                                    device=device)\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXmUfrBovrGl"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.gru = nn.GRU(emb_dim, hid_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, seq):\n",
        "        #seq = [seq len, batch size]\n",
        "        embedded = self.dropout(self.embedding(seq)) # out shape [seq len, batch size, emb dim]\n",
        "        outputs, hidden = self.gru(embedded)\n",
        "        #outputs = [seq len, batch size, hid dim*n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        return hidden"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2cDn7fjwDCk"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.hid_dim = hid_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.gru = nn.GRU(emb_dim+hid_dim, hid_dim) #emb_dim is current input (target)+hid_dim is context vector from encoder\n",
        "        self.out = nn.Linear(emb_dim+hid_dim*2, output_dim) #hid dim*2 = context vector encoder + prev decoder hidden states \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    def forward(self, input, hidden, context):\n",
        "        #input = [batch size]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #context = [n layers * n directions, batch size, hid dim]\n",
        "        input = input.unsqueeze(0) # [1, batch size]\n",
        "\n",
        "        embedded = self.dropout(self.embedding(input)) # [1, batch size, emb dim]\n",
        "        emb_concat = torch.cat((embedded, context), dim=2)\n",
        "        \n",
        "        output, hidden = self.gru(emb_concat, hidden) # decoder's first hidden state h0 is from encoder last hidden state\n",
        "        output = torch.cat((embedded.squeeze(0), hidden.squeeze(0), context.squeeze(0)), dim=1)\n",
        "        pred = self.out(output)\n",
        "        return pred, hidden"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9e8rwaWwJRs"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        assert encoder.hid_dim == decoder.hid_dim, \"hidden dimensions of encoder and decoder must be equal!\"\n",
        "\n",
        "    def forward(self, src, trg=None, teacher_forcing_ratio=0.5):\n",
        "        if trg is None:\n",
        "            trg = torch.zeros((25, src.shape[1])).fill_(2).long().to(src.device)\n",
        "            assert teacher_forcing_ratio == 0, 'techer forcing must be 0 during inference, i.e. use the y prediction'\n",
        "\n",
        "        batch_size = trg.shape[1]\n",
        "        max_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device) #tensor to store decoder outputs\n",
        "        context = self.encoder(src) #last hidden state of the encoder. same for all time step\n",
        "        hidden = context #initial hidden state of the decoder is the last hidden state of encoder\n",
        "        \n",
        "        input = trg[0,:] #first input to the decoder is the <sos> token which is the first row in trg\n",
        "        for t in range(1, max_len):\n",
        "            output, hidden = self.decoder(input, hidden, context)\n",
        "            outputs[t] = output\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.max(1)[1] #the prediction of the next output\n",
        "            input = (trg[t] if teacher_force else top1) #the next input for decoder is either the real y or the prediction\n",
        "        return outputs"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDJDERBLwQJd"
      },
      "source": [
        "TRAINING PROCESS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4x2QtQ5twLR4"
      },
      "source": [
        "def train(model, train_it, optimizer, criterion, clip):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for i, batch in tdqm(enumerate(train_it)):\n",
        "        src = batch.jp\n",
        "        trg = batch.en\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, trg)\n",
        "        loss = criterion(output[1:].view(-1, output.shape[-1]), trg[1:].view(-1))\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "    return epoch_loss/ len(train_it)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLNn5wMzwTeP"
      },
      "source": [
        "def evaluate(model, data_it, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    for i, batch in tqdm(enumerate(data_it)):\n",
        "        src = batch.jp\n",
        "        trg = batch.en\n",
        "        output = model(src, trg, 0)\n",
        "        loss = criterion(output[1:].view(-1, output.shape[-1]), trg[1:].view(-1))\n",
        "        epoch_loss += loss.item()\n",
        "    return epoch_loss/ len(data_it)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z2tZLRWwVA7"
      },
      "source": [
        "input_dim = len(SRC.vocab)\n",
        "out_dim = len(TRG.vocab)\n",
        "enc_emb_dim = 128\n",
        "dec_emb_dim = 128\n",
        "hidden_dim = 256\n",
        "nlayers = 2\n",
        "enc_dropout = 0.3\n",
        "dec_dropout = 0.3\n",
        "enc = Encoder(input_dim, enc_emb_dim, hidden_dim,  enc_dropout)\n",
        "dec = Decoder(out_dim, dec_emb_dim, hidden_dim, dec_dropout)\n",
        "model = Seq2Seq(enc, dec, device).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "pad_idx = TRG.vocab.stoi['<pad>']\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHnLpPUVwY_C"
      },
      "source": [
        "epoch = 10\n",
        "clip = 1\n",
        "savedir = 'models'\n",
        "model_save_path = os.path.join(savedir, 's2smodel.pt')\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "if not os.path.isdir(f'{savedir}'):\n",
        "    os.makedirs(f'{savedir}')\n",
        "for ep in range(epoch):\n",
        "    train_loss = train(model, train_it, optimizer, criterion, clip)\n",
        "    valid_loss = evaluate(model, valid_it, criterion)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), model_save_path)\n",
        "    \n",
        "    print (f'epoch: {ep+1:03} | train loss: {train_loss: .3f} | \\\n",
        "    train_ppl: {math.exp(train_loss):7.3f} | Val. Loss: {valid_loss:.3f} | \\\n",
        "     Val. PPL: {math.exp(valid_loss):7.3f} |')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}